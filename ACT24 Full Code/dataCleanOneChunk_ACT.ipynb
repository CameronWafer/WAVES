{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f5abd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1858f1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time_Absolute_dmy_hmsf</th>\n",
       "      <th>Date_dmy</th>\n",
       "      <th>Time_Absolute_hms</th>\n",
       "      <th>Time_Absolute_f</th>\n",
       "      <th>Time_Relative_hmsf</th>\n",
       "      <th>Time_Relative_hms</th>\n",
       "      <th>Time_Relative_f</th>\n",
       "      <th>Time_Relative_sf</th>\n",
       "      <th>Duration_sf</th>\n",
       "      <th>Observation</th>\n",
       "      <th>Event_Log</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Modifier_1</th>\n",
       "      <th>Modifier_2</th>\n",
       "      <th>Modifier_3</th>\n",
       "      <th>Event_Type</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24-03-2020 11:17:41.259</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>11:17:41</td>\n",
       "      <td>259</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00137</td>\n",
       "      <td>42.5983</td>\n",
       "      <td>ID_102_01_C</td>\n",
       "      <td>Event log</td>\n",
       "      <td>LA- stand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24-03-2020 11:17:41.259</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>11:17:41</td>\n",
       "      <td>259</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00137</td>\n",
       "      <td>53.7145</td>\n",
       "      <td>ID_102_01_C</td>\n",
       "      <td>Event log</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>State start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24-03-2020 11:18:23.857</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>11:18:23</td>\n",
       "      <td>857</td>\n",
       "      <td>00:42.6</td>\n",
       "      <td>0:00:42</td>\n",
       "      <td>597</td>\n",
       "      <td>42.59690</td>\n",
       "      <td>17.3160</td>\n",
       "      <td>ID_102_01_C</td>\n",
       "      <td>Event log</td>\n",
       "      <td>WA- walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24-03-2020 11:18:34.973</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>11:18:34</td>\n",
       "      <td>973</td>\n",
       "      <td>00:53.7</td>\n",
       "      <td>0:00:53</td>\n",
       "      <td>713</td>\n",
       "      <td>53.71310</td>\n",
       "      <td>535.6290</td>\n",
       "      <td>ID_102_01_C</td>\n",
       "      <td>Event log</td>\n",
       "      <td>TRAV- walking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24-03-2020 11:18:41.173</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>11:18:41</td>\n",
       "      <td>173</td>\n",
       "      <td>00:59.9</td>\n",
       "      <td>0:00:59</td>\n",
       "      <td>913</td>\n",
       "      <td>59.91290</td>\n",
       "      <td>14.0161</td>\n",
       "      <td>ID_102_01_C</td>\n",
       "      <td>Event log</td>\n",
       "      <td>WA- descend stairs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State start</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_Time_Absolute_dmy_hmsf    Date_dmy Time_Absolute_hms  Time_Absolute_f  \\\n",
       "0     24-03-2020 11:17:41.259  24-03-2020          11:17:41              259   \n",
       "3     24-03-2020 11:17:41.259  24-03-2020          11:17:41              259   \n",
       "5     24-03-2020 11:18:23.857  24-03-2020          11:18:23              857   \n",
       "7     24-03-2020 11:18:34.973  24-03-2020          11:18:34              973   \n",
       "9     24-03-2020 11:18:41.173  24-03-2020          11:18:41              173   \n",
       "\n",
       "                                  Time_Relative_hmsf Time_Relative_hms  \\\n",
       "0  ##############################################...           0:00:00   \n",
       "3  ##############################################...           0:00:00   \n",
       "5                                            00:42.6           0:00:42   \n",
       "7                                            00:53.7           0:00:53   \n",
       "9                                            00:59.9           0:00:59   \n",
       "\n",
       "   Time_Relative_f  Time_Relative_sf  Duration_sf  Observation  Event_Log  \\\n",
       "0                1           0.00137      42.5983  ID_102_01_C  Event log   \n",
       "3                1           0.00137      53.7145  ID_102_01_C  Event log   \n",
       "5              597          42.59690      17.3160  ID_102_01_C  Event log   \n",
       "7              713          53.71310     535.6290  ID_102_01_C  Event log   \n",
       "9              913          59.91290      14.0161  ID_102_01_C  Event log   \n",
       "\n",
       "             Behavior Modifier_1 Modifier_2  \\\n",
       "0           LA- stand        NaN        NaN   \n",
       "3        WRK- general        NaN        NaN   \n",
       "5            WA- walk        NaN   moderate   \n",
       "7       TRAV- walking        NaN        NaN   \n",
       "9  WA- descend stairs        NaN   moderate   \n",
       "\n",
       "                          Modifier_3   Event_Type Comment  Unnamed: 17  \\\n",
       "0                                NaN  State start     NaN          NaN   \n",
       "3  SP- Education and Health Services  State start     NaN          NaN   \n",
       "5                                NaN  State start     NaN          NaN   \n",
       "7                                NaN  State start     NaN          NaN   \n",
       "9                                NaN  State start     NaN          NaN   \n",
       "\n",
       "   Unnamed: 18  \n",
       "0          NaN  \n",
       "3          NaN  \n",
       "5          NaN  \n",
       "7          NaN  \n",
       "9          NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACT import (both log and behavior)\n",
    "behav_act_df = pd.read_csv(\"C:/Users/HELIOS-300/Downloads/ACT24_behposture_event(in).csv\")\n",
    "log_df = pd.read_csv(\"C:/Users/HELIOS-300/Downloads/do_log_final_behavior(in).csv\")\n",
    "\n",
    "behav_act_df = behav_act_df[behav_act_df[\"Event_Type\"] == \"State start\"]\n",
    "behav_act_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity events: 833, Posture events: 6904, Other: 151\n",
      "Activity expanded: 511685, Posture expanded: 507223\n",
      "Merged result: 511690 rows\n",
      "After encoding, behav_act_df_7 shape: (499132, 23)\n",
      "activity_type NaN: 0\n",
      "posture_wbm NaN: 1870\n",
      "Stabilization: activity_type 0 -> 0, posture_wbm 1870 -> 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>broad_domain</th>\n",
       "      <th>waves_domain</th>\n",
       "      <th>posture_wbm</th>\n",
       "      <th>posture_broad</th>\n",
       "      <th>posture_waves</th>\n",
       "      <th>waves_sedentary</th>\n",
       "      <th>intensity</th>\n",
       "      <th>start_time_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>08:21:12 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>08:21:12 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>08:21:12 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>08:21:12 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>08:21:12 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  obs  rel_time activity_type    broad_domain    waves_domain  \\\n",
       "0  102    1  00:00:00  work_general  work_education  work_education   \n",
       "1  102    1  00:00:01  work_general  work_education  work_education   \n",
       "2  102    1  00:00:02  work_general  work_education  work_education   \n",
       "3  102    1  00:00:03  work_general  work_education  work_education   \n",
       "4  102    1  00:00:04  work_general  work_education  work_education   \n",
       "\n",
       "  posture_wbm posture_broad posture_waves waves_sedentary intensity  \\\n",
       "0       stand    stand_move    mixed_move          active     light   \n",
       "1       stand    stand_move    mixed_move          active     light   \n",
       "2       stand    stand_move    mixed_move          active     light   \n",
       "3       stand    stand_move    mixed_move          active     light   \n",
       "4       stand    stand_move    mixed_move          active     light   \n",
       "\n",
       "  start_time_new  \n",
       "0    08:21:12 AM  \n",
       "1    08:21:12 AM  \n",
       "2    08:21:12 AM  \n",
       "3    08:21:12 AM  \n",
       "4    08:21:12 AM  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Behavior ACT data cleaning - FIXED VERSION\n",
    "# Separates activity and posture tracks to preserve simultaneous events at same timestamp\n",
    "\n",
    "# quick log data cleaning\n",
    "log_df['date'] = pd.to_datetime({\n",
    "    'year': pd.to_numeric(log_df['start_year'], errors='coerce'),\n",
    "    'month': pd.to_numeric(log_df['start_month'], errors='coerce'),\n",
    "    'day': pd.to_numeric(log_df['start_day'], errors='coerce'),\n",
    "}, errors='coerce').dt.strftime('%#m/%#d/%Y')\n",
    "\n",
    "log_df.drop(columns=[\"start_month\", \"start_day\", \"start_year\"], inplace=True)\n",
    "log_df2 = log_df.loc[:, [\"id\", \"do\", \"date\", \"start_time\"]].copy()\n",
    "\n",
    "# Convert log_df2 start_time to 24-hour HH:MM:SS\n",
    "s = log_df2['start_time'].astype(str).str.strip()\n",
    "\n",
    "# Support both with and without seconds\n",
    "_dt1 = pd.to_datetime(s, format='%I:%M:%S %p', errors='coerce')\n",
    "_dt2 = pd.to_datetime(s, format='%I:%M %p', errors='coerce')\n",
    "\n",
    "log_df2.loc[:, 'start_time'] = _dt1.fillna(_dt2).dt.strftime('%H:%M:%S')\n",
    "log_df2.loc[:, 'date_time'] = log_df2['date'].astype(str).str.strip() + ' ' + log_df2['start_time'].astype(str).str.strip()\n",
    "\n",
    "log_df2.rename(columns={\"start_time\" : \"time\", \"do\" : \"obs\"}, inplace=True)\n",
    "log_df2 = log_df2.drop(columns=[\"time\", \"date_time\"])\n",
    "\n",
    "\n",
    "# Start behavior cleaning\n",
    "behav_act_df1 = behav_act_df.drop(columns=[\"Date_Time_Absolute_dmy_hmsf\", \n",
    "\"Date_dmy\", \n",
    "\"Time_Absolute_hms\", \n",
    "\"Time_Absolute_f\", \n",
    "\"Unnamed: 17\", \n",
    "\"Unnamed: 18\",\n",
    "\"Event_Log\"])\n",
    "\n",
    "# add \"id\" and \"do\" style ID's from LOG into ACT behavior file so we can join\n",
    "def add_id_do_split(df, source_col='Observation', id_col='id', do_col='do', inplace=True):\n",
    "    parts = df[source_col].str.split('_', expand=True)\n",
    "    id_series = pd.to_numeric(parts[1], errors='coerce').astype('Int64')\n",
    "    do_series = pd.to_numeric(parts[2], errors='coerce').astype('Int64')\n",
    "    if inplace:\n",
    "        df[id_col] = id_series\n",
    "        df[do_col] = do_series\n",
    "        return df\n",
    "    out = df.copy()\n",
    "    out[id_col] = id_series\n",
    "    out[do_col] = do_series\n",
    "    return out\n",
    "\n",
    "# add a column from LOG onto Behavior based on \"id\" and \"do\"\n",
    "def add_col_from_other_df_merge(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    left_keys: list,\n",
    "    right_keys: list,\n",
    "    right_value_col: str,\n",
    "    new_col_name: str | None = None,\n",
    "    how: str = 'left',\n",
    "    validate: str = 'many_to_one'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a single column from `right` to `left` by joining on two (or more) key columns.\n",
    "    \"\"\"\n",
    "    if new_col_name is None:\n",
    "        new_col_name = right_value_col\n",
    "\n",
    "    right_subset = right[right_keys + [right_value_col]].rename(\n",
    "        columns={right_value_col: new_col_name}\n",
    "    )\n",
    "    merged = left.merge(\n",
    "        right_subset,\n",
    "        how=how,\n",
    "        left_on=left_keys,\n",
    "        right_on=right_keys,\n",
    "        validate=validate\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "behav_act_df2 = add_id_do_split(behav_act_df1)\n",
    "\n",
    "behav_act_df3 = add_col_from_other_df_merge(\n",
    "    left=behav_act_df2,                 # main df (to put columns into)\n",
    "    right=log_df,               # other df (to pull the columns from)\n",
    "    left_keys=['id', 'do'],\n",
    "    right_keys=['id', 'do'],\n",
    "    right_value_col='start_time',      # column from df_right to bring over\n",
    "    how='left',\n",
    "    validate='many_to_one'        # set 'one_to_one' to enforce uniqueness if applicable (not here yet really)\n",
    ")\n",
    "\n",
    "series_temp = behav_act_df3.pop(\"start_time\")\n",
    "behav_act_df3.insert(0, \"start_time\", series_temp)\n",
    "\n",
    "behav_act_df4 = behav_act_df3.drop(index=behav_act_df3.index[behav_act_df3[\"Event_Type\"] != \"State start\"])\n",
    "\n",
    "# parse start_time (supports \"8:20:19 AM\" and \"8:20 AM\")\n",
    "s = behav_act_df4['start_time'].astype(str).str.strip()\n",
    "dt1 = pd.to_datetime(s, format='%I:%M:%S %p', errors='coerce')\n",
    "dt2 = pd.to_datetime(s, format='%I:%M %p', errors='coerce')\n",
    "behav_act_df4['start_time_dt'] = dt1.fillna(dt2)\n",
    "\n",
    "# parse Time_Relative_hmsf (supports \"HH:MM:SS(.f)\", \"MM:SS(.f)\", \"SS(.f)\")\n",
    "r = behav_act_df4['Time_Relative_hmsf'].astype(str).str.strip()\n",
    "r = r.str.replace(',', '.', regex=False).str.replace(';', '.', regex=False)\n",
    "\n",
    "td = pd.Series(pd.NaT, index=r.index, dtype='timedelta64[ns]')\n",
    "mask_hms = r.str.count(':') == 2\n",
    "mask_ms  = r.str.count(':') == 1\n",
    "mask_sec = r.str.fullmatch(r'/d+(/./d+)?')\n",
    "mask_blank = r.eq('') | r.str.lower().isin(['nan', 'none'])\n",
    "\n",
    "td.loc[mask_hms] = pd.to_timedelta(r[mask_hms], errors='coerce')\n",
    "td.loc[mask_ms]  = pd.to_timedelta('00:' + r[mask_ms], errors='coerce')  # prefix hours\n",
    "td.loc[mask_sec] = pd.to_timedelta(r[mask_sec].astype(float), unit='s')\n",
    "td.loc[mask_blank] = pd.NaT\n",
    "\n",
    "behav_act_df4['time_relative_td'] = td\n",
    "\n",
    "# sum to produce the new start time\n",
    "behav_act_df5 = behav_act_df4.copy()\n",
    "behav_act_df5['start_time_new'] = behav_act_df5['start_time_dt'] + behav_act_df5['time_relative_td']\n",
    "\n",
    "# time-only display strings (no date)\n",
    "behav_act_df5['start_time_str'] = behav_act_df5['start_time_dt'].dt.strftime('%I:%M:%S %p')\n",
    "behav_act_df5['start_time_new_str'] = behav_act_df5['start_time_new'].dt.strftime('%I:%M:%S %p')\n",
    "\n",
    "# drop intermediates, rename, and position between the first two columns\n",
    "drop_cols = [c for c in ['start_time_dt','time_relative_td','start_time_new','start_time_str'] if c in behav_act_df5.columns]\n",
    "behav_act_df5 = behav_act_df5.drop(columns=drop_cols)\n",
    "\n",
    "behav_act_df5 = behav_act_df5.rename(columns={'start_time_new_str': 'start_time_new'})\n",
    "\n",
    "first_cols = ['start_time', 'start_time_new', 'Time_Relative_hmsf']\n",
    "other_cols = [c for c in behav_act_df5.columns if c not in first_cols]\n",
    "behav_act_df5 = behav_act_df5[first_cols + other_cols]\n",
    "\n",
    "# shared helper func(s)\n",
    "def _parse_hms_to_seconds(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.str.replace(',', '.', regex=False).str.replace(';', '.', regex=False)\n",
    "\n",
    "    td = pd.Series(pd.NaT, index=s.index, dtype='timedelta64[ns]')\n",
    "    mask_hms = s.str.count(':') == 2           # H:M:S(.f)\n",
    "    mask_ms  = s.str.count(':') == 1           # M:S(.f)\n",
    "    mask_sec = s.str.fullmatch(r'/d+(/./d+)?') # seconds only\n",
    "    mask_blank = s.eq('') | r.str.lower().isin(['nan', 'none'])\n",
    "\n",
    "    td.loc[mask_hms] = pd.to_timedelta(s[mask_hms], errors='coerce')\n",
    "    td.loc[mask_ms]  = pd.to_timedelta('00:' + s[mask_ms], errors='coerce')\n",
    "    if mask_sec.any():\n",
    "        td.loc[mask_sec] = pd.to_timedelta(s[mask_sec].astype(float), unit='s')\n",
    "    td.loc[mask_blank] = pd.NaT\n",
    "\n",
    "    return td.dt.total_seconds()\n",
    "\n",
    "def _format_hms(seconds_float: float, decimals: int = 0) -> str:\n",
    "    if pd.isna(seconds_float):\n",
    "        return np.nan\n",
    "    scale = 10 ** decimals\n",
    "    total_units = int(round(seconds_float * scale))\n",
    "    secs = total_units // scale\n",
    "    frac_units = total_units % scale\n",
    "    h = secs // 3600\n",
    "    m = (secs % 3600) // 60\n",
    "    s = secs % 60\n",
    "    if decimals == 0:\n",
    "        return f'{h:02d}:{m:02d}:{s:02d}'\n",
    "    return f'{h:02d}:{m:02d}:{s:02d}.{frac_units:0{decimals}d}'\n",
    "\n",
    "# Normalization for classification\n",
    "_def_ws_re = re.compile(r\"/s+\")\n",
    "\n",
    "def _normalize_behavior(value: object) -> str | None:\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    s = str(value).strip().lower()\n",
    "    s = s.replace('–', '-').replace('—', '-')\n",
    "    s = _def_ws_re.sub(' ', s)\n",
    "    return s\n",
    "\n",
    "# Classify behavior as domain activity or posture\n",
    "_domain_prefixes = {\n",
    "    'sl-', 'pc-', 'ha-', 'ca-', 'wrk-', 'edu-', 'org-', 'pur-', 'eat-', 'les-', 'ex-', 'trav-', 'other-'\n",
    "}\n",
    "_posture_prefixes = {\n",
    "    'sb-', 'la-', 'wa-', 'sp-'\n",
    "}\n",
    "\n",
    "def _classify_behavior(behavior_val):\n",
    "    \"\"\"Returns 'activity', 'posture', or 'other'\"\"\"\n",
    "    norm = _normalize_behavior(behavior_val)\n",
    "    if not norm:\n",
    "        return 'other'\n",
    "    # Check domain prefixes\n",
    "    for prefix in _domain_prefixes:\n",
    "        if norm.startswith(prefix):\n",
    "            return 'activity'\n",
    "    # Check posture prefixes\n",
    "    for prefix in _posture_prefixes:\n",
    "        if norm.startswith(prefix):\n",
    "            return 'posture'\n",
    "    # Handle special cases\n",
    "    if norm in {'private/not coded', 'start posture', 'start behavior'}:\n",
    "        return 'other'\n",
    "    return 'other'\n",
    "\n",
    "df = behav_act_df5.copy()\n",
    "df['_seconds'] = _parse_hms_to_seconds(df['Time_Relative_hms'])\n",
    "df = df.sort_values(['Observation', '_seconds'], kind='mergesort')\n",
    "\n",
    "# Classify each row\n",
    "df['_track'] = df['Behavior'].apply(_classify_behavior)\n",
    "\n",
    "# Split into activity and posture dataframes\n",
    "activity_df = df[df['_track'] == 'activity'].copy()\n",
    "posture_df = df[df['_track'] == 'posture'].copy()\n",
    "\n",
    "print(f\"Activity events: {len(activity_df)}, Posture events: {len(posture_df)}, Other: {(df['_track'] == 'other').sum()}\")\n",
    "\n",
    "# --- Expand activity track to per-second ---\n",
    "def expand_track_to_seconds(track_df, track_name='track'):\n",
    "    \"\"\"Expand a track (activity or posture) to per-second resolution\"\"\"\n",
    "    out_groups = []\n",
    "    \n",
    "    for obs_value, g in track_df.groupby('Observation', sort=False):\n",
    "        g = g.copy()\n",
    "        g = g[~g['_seconds'].isna()]\n",
    "        if g.empty:\n",
    "            continue\n",
    "        \n",
    "        g['_event_second'] = np.floor(g['_seconds']).astype(int)\n",
    "        \n",
    "        # Keep last within each second\n",
    "        g_last = (\n",
    "            g.sort_values(['_event_second', '_seconds'], kind='mergesort')\n",
    "             .drop_duplicates(subset=['_event_second'], keep='last')\n",
    "        )\n",
    "        \n",
    "        min_s = float(g['_seconds'].min())\n",
    "\n",
    "        # Calculate end time for each event: start_time + duration\n",
    "        if 'Duration_sf' in g.columns:\n",
    "            # Convert Duration_sf to numeric, handling any missing values\n",
    "            g['_duration'] = pd.to_numeric(g['Duration_sf'], errors='coerce').fillna(0)\n",
    "            # Calculate end time for each event\n",
    "            g['_end_time'] = g['_seconds'] + g['_duration']\n",
    "            # Use the maximum end time to determine expansion range\n",
    "            max_end_s = float(g['_end_time'].max())\n",
    "            max_s = max(float(g['_seconds'].max()), max_end_s)\n",
    "        else:\n",
    "            # Fallback: if Duration_sf not available, use original logic\n",
    "            max_s = float(g['_seconds'].max())\n",
    "        \n",
    "        if np.isclose(min_s, 0.0):\n",
    "            start_second = 0\n",
    "            flag_first = False\n",
    "        else:\n",
    "            start_second = int(np.ceil(min_s))\n",
    "            flag_first = True\n",
    "        \n",
    "        end_second = int(np.floor(max_s))\n",
    "        if end_second < start_second:\n",
    "            end_second = start_second\n",
    "        \n",
    "        seconds_grid = np.arange(start_second, end_second + 1, dtype=int)\n",
    "        \n",
    "        base = g_last.set_index('_event_second').sort_index()\n",
    "        first_index_second = int(np.floor(min_s))\n",
    "        full_index = np.arange(first_index_second, end_second + 1, dtype=int)\n",
    "        aligned = base.reindex(full_index).ffill()\n",
    "        \n",
    "        take = aligned.loc[seconds_grid].copy()\n",
    "        take.reset_index(drop=False, inplace=True)\n",
    "        take.rename(columns={'_event_second': '_second'}, inplace=True)\n",
    "        \n",
    "        # Time strings\n",
    "        time_strings = [_format_hms(s, decimals=0) for s in seconds_grid]\n",
    "        if flag_first and len(time_strings) > 0:\n",
    "            flagged = min_s + 0.01\n",
    "            time_strings[0] = _format_hms(flagged, decimals=2)\n",
    "        \n",
    "        take['Time_Relative_hms_new'] = time_strings\n",
    "        \n",
    "        out_groups.append(take)\n",
    "    \n",
    "    if not out_groups:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    result = pd.concat(out_groups, axis=0, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "# Expand both tracks\n",
    "activity_expanded = expand_track_to_seconds(activity_df, 'activity')\n",
    "posture_expanded = expand_track_to_seconds(posture_df, 'posture')\n",
    "\n",
    "print(f\"Activity expanded: {len(activity_expanded)}, Posture expanded: {len(posture_expanded)}\")\n",
    "\n",
    "# --- Merge activity and posture on (Observation, second) ---\n",
    "\n",
    "# Keep columns needed from each track (including modifiers from BOTH)\n",
    "activity_cols_keep = ['Observation', '_second', 'Time_Relative_hms_new', 'Behavior', 'Modifier_1', 'Modifier_2', 'Modifier_3', \n",
    "                      'start_time_new', 'id', 'do']\n",
    "posture_cols_keep = ['Observation', '_second', 'Behavior', 'Modifier_2']  # Modifier_2 for intensity\n",
    "\n",
    "activity_subset = activity_expanded[activity_cols_keep].rename(columns={'Behavior': 'Behavior_activity', \n",
    "                                                                          'Modifier_1': 'Modifier_1_activity',\n",
    "                                                                          'Modifier_2': 'Modifier_2_activity',\n",
    "                                                                          'Modifier_3': 'Modifier_3'})\n",
    "posture_subset = posture_expanded[posture_cols_keep].rename(columns={'Behavior': 'Behavior_posture',\n",
    "                                                                       'Modifier_2': 'Modifier_2_posture'})\n",
    "\n",
    "# Full outer merge to get all seconds from both tracks\n",
    "merged = activity_subset.merge(\n",
    "    posture_subset,\n",
    "    on=['Observation', '_second'],\n",
    "    how='outer',\n",
    "    suffixes=('', '_posture')\n",
    ")\n",
    "\n",
    "# Fill observation metadata forward\n",
    "merged = merged.sort_values(['Observation', '_second'], kind='mergesort')\n",
    "# NOTE: Time_Relative_hms_new should NOT be forward-filled - it must be derived from _second\n",
    "for col in ['id', 'do', 'start_time_new']:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged.groupby('Observation')[col].ffill().bfill()\n",
    "\n",
    "# Regenerate Time_Relative_hms_new from _second to ensure uniqueness\n",
    "# This fixes the issue where forward-fill was creating duplicate time values\n",
    "merged['Time_Relative_hms_new'] = merged['_second'].apply(_format_hms)\n",
    "\n",
    "# Combine Behaviors: use activity behavior for encoding activity_type, posture behavior for encoding posture\n",
    "merged['Behavior'] = merged['Behavior_activity'].fillna(merged['Behavior_posture'])\n",
    "\n",
    "# Combine Modifier_1 and Modifier_3 (activity-related modifiers)\n",
    "merged['Modifier_1'] = merged['Modifier_1_activity']\n",
    "merged['Modifier_3'] = merged['Modifier_3']\n",
    "\n",
    "# Combine Modifier_2 (intensity): prefer posture track, fallback to activity track\n",
    "merged['Modifier_2'] = merged['Modifier_2_posture'].fillna(merged['Modifier_2_activity'])\n",
    "\n",
    "# Rename _second to rel_time for final output\n",
    "merged['rel_time'] = merged['Time_Relative_hms_new']\n",
    "\n",
    "behav_act_df_6 = merged.copy()\n",
    "\n",
    "# Cleanup only intermediate helper columns, but KEEP Behavior_activity and Behavior_posture for encoding!\n",
    "for c in ['_seconds', '_second', '_track', 'Modifier_1_activity', 'Modifier_2_activity', 'Modifier_2_posture']:\n",
    "    if c in behav_act_df_6.columns:\n",
    "        behav_act_df_6 = behav_act_df_6.drop(columns=c)\n",
    "\n",
    "print(f\"Merged result: {len(behav_act_df_6)} rows\")\n",
    "\n",
    "\n",
    "# ENCODING: Activity and Posture (independent tracks, same as before)\n",
    "behav_act_df_7 = behav_act_df_6.copy()\n",
    "\n",
    "# Mapping from canonical Activity_Type to (activity_type, broad_domain, waves_domain)\n",
    "_activity_type_to_meta = {\n",
    "    'SL- Sleep': ('sleep', 'sleep', 'household_personal'),\n",
    "    'PC- Groom, Health-Related': ('pc_groom', 'personal', 'household_personal'),\n",
    "    'PC- Other Personal Care': ('pc_other', 'personal', 'household_personal'),\n",
    "    'HA- Housework': ('ha_housework', 'household', 'household_personal'),\n",
    "    'HA- Food Prep and Cleanup': ('ha_food', 'household', 'household_personal'),\n",
    "    'HA- Interior Maintenance, Repair, & Decoration': ('ha_interior', 'maintenance_repair', 'household_personal'),\n",
    "    'HA- Exterior Maintenance, Repair, & Decoration': ('ha_exterior', 'maintenance_repair', 'household_personal'),\n",
    "    'HA- Lawn, Garden and Houseplants': ('ha_lawn', 'lawn_garden', 'household_personal'),\n",
    "    'HA- Animals and Pets': ('ha_pets', 'household', 'household_personal'),\n",
    "    'HA- Household Management/Other household activities': ('ha_other', 'household', 'household_personal'),\n",
    "    'CA- Caring for and Helping Children': ('care_children', 'household', 'household_personal'),\n",
    "    'CA- Caring for and Helping Adults': ('care_adults', 'household', 'household_personal'),\n",
    "    'WRK- General**': ('work_general', 'work_education', 'work_education'),\n",
    "    'WRK- Desk/Screen Based': ('work_screen', 'work_education', 'work_education'),\n",
    "    'EDU- Taking Class, Research, Homework': ('edu_class', 'work_education', 'work_education'),\n",
    "    'EDU- Extracurricular': ('edu_other', 'work_education', 'work_education'),\n",
    "    'ORG- Church, Spiritual': ('com_church', 'purchase_other', 'purchase_other'),\n",
    "    'Volunteer Work (ORG - Volunteer Work)': ('com_volunteer', 'purchase_other', 'purchase_other'),\n",
    "    'PUR- Purchasing Goods and Services': ('com_purchase', 'purchase_other', 'purchase_other'),\n",
    "    'EAT- Eating and Drinking, Waiting': ('ha_eat', 'personal', 'household_personal'),\n",
    "    'LES- Socializing, Communicating, Non-Screen Based': ('les_social', 'leisure', 'leisure'),\n",
    "    'LES- Screen-Based (TV, Video Game, Computer, Phone)': ('les_screen', 'Leisure_Screen', 'leisure'),\n",
    "    'EX- Participating in Sport, Exercise or Recreation***': ('ex_sport', 'exercise', 'leisure'),\n",
    "    'EX- Attending Sport, Exercise Recreation Event, or Performance': ('les_attend', 'leisure', 'leisure'),\n",
    "    'TRAV- Passenger (Car/Truck/Motorcycle)': ('trav_pass', 'Trav_car', 'transportation'),\n",
    "    'TRAV- Driver (Car/Truck/Motorcycle)': ('trav_drive', 'Trav_car', 'transportation'),\n",
    "    'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)': ('trav_pass', 'Trav_public', 'transportation'),\n",
    "    'TRAV- Biking': ('trav_bike', 'active_transportation', 'transportation'),\n",
    "    'TRAV-Walking': ('trav_walk', 'active_transportation', 'transportation'),\n",
    "    'TRAV- General': ('trav_other', 'transportation', 'transportation'),\n",
    "    'OTHER- Non-Codable (delete these rows from dataset)': ('non_codable', 'non_codable', 'non_codable'),\n",
    "}\n",
    "\n",
    "# Map raw Behavior values to canonical Activity_Type keys above\n",
    "_alias_to_activity_type = {\n",
    "    'sl- sleep': 'SL- Sleep',\n",
    "    'pc- groom, health-related': 'PC- Groom, Health-Related',\n",
    "    'pc- other personal care': 'PC- Other Personal Care',\n",
    "    'ha- housework': 'HA- Housework',\n",
    "    'ha- food prep and cleanup': 'HA- Food Prep and Cleanup',\n",
    "    'ha- interior maintenance, repair, & decoration': 'HA- Interior Maintenance, Repair, & Decoration',\n",
    "    'ha- exterior maintenance, repair, & decoration': 'HA- Exterior Maintenance, Repair, & Decoration',\n",
    "    'ha- lawn, garden and houseplants': 'HA- Lawn, Garden and Houseplants',\n",
    "    'ha- animals and pets': 'HA- Animals and Pets',\n",
    "    'ha- household management/other household activities': 'HA- Household Management/Other household activities',\n",
    "    'ca- caring for and helping children': 'CA- Caring for and Helping Children',\n",
    "    'ca- caring for and helping adults': 'CA- Caring for and Helping Adults',\n",
    "    'wrk- general': 'WRK- General**',\n",
    "    'wrk- screen based': 'WRK- Desk/Screen Based',\n",
    "    'edu- taking class, research, homework': 'EDU- Taking Class, Research, Homework',\n",
    "    'edu- extracurricular': 'EDU- Extracurricular',\n",
    "    'org- church, spiritual': 'ORG- Church, Spiritual',\n",
    "    'org- volunteer': 'Volunteer Work (ORG - Volunteer Work)',\n",
    "    'pur- purchasing goods and services': 'PUR- Purchasing Goods and Services',\n",
    "    'eat- eating and drinking, waiting': 'EAT- Eating and Drinking, Waiting',\n",
    "    'les- socializing, communicating, leisure time not screen': 'LES- Socializing, Communicating, Non-Screen Based',\n",
    "    'les- screen based leisure time (tv, video game, computer)': 'LES- Screen-Based (TV, Video Game, Computer, Phone)',\n",
    "    'les- screen-based (tv, video game, computer, phone)': 'LES- Screen-Based (TV, Video Game, Computer, Phone)',\n",
    "    'ex- participating in sport, exercise or recreation': 'EX- Participating in Sport, Exercise or Recreation***',\n",
    "    'ex- attending sport, recreational event, or performance': 'EX- Attending Sport, Exercise Recreation Event, or Performance',\n",
    "    'trav- passenger (car/truck/motorcycle)': 'TRAV- Passenger (Car/Truck/Motorcycle)',\n",
    "    'trav- driver (car/truck/motorcycle)': 'TRAV- Driver (Car/Truck/Motorcycle)',\n",
    "    'trav- passenger (bus, train, tram, plane, boat, ship)': 'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)',\n",
    "    'trav- biking': 'TRAV- Biking',\n",
    "    'trav- walking': 'TRAV-Walking',\n",
    "    'trav-walking': 'TRAV-Walking',\n",
    "    'trav- general': 'TRAV- General',\n",
    "    'other- non codable': 'OTHER- Non-Codable (delete these rows from dataset)',\n",
    "    'private/not coded': 'OTHER- Non-Codable (delete these rows from dataset)',\n",
    "}\n",
    "\n",
    "def _map_behavior_to_activity_type(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('les- screen'):\n",
    "        return 'LES- Screen-Based (TV, Video Game, Computer, Phone)'\n",
    "    if s.startswith('trav- passenger (bus'):\n",
    "        return 'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)'\n",
    "    return _alias_to_activity_type.get(s)\n",
    "\n",
    "# Build Activity_Type from Behavior_activity column (preserved from activity track)\n",
    "if 'Behavior_activity' in behav_act_df_7.columns:\n",
    "    behav_act_df_7['Activity_Type'] = behav_act_df_7['Behavior_activity'].apply(_map_behavior_to_activity_type)\n",
    "else:\n",
    "    # Fallback: classify on the fly from merged Behavior\n",
    "    behav_act_df_7['Activity_Type'] = behav_act_df_7['Behavior'].apply(\n",
    "        lambda b: _map_behavior_to_activity_type(b) if _classify_behavior(b) == 'activity' else None\n",
    "    )\n",
    "\n",
    "# EX modifier handling\n",
    "if 'Modifier_1' in behav_act_df_7.columns:\n",
    "    mask_ex = behav_act_df_7['Activity_Type'] == 'EX- Participating in Sport, Exercise or Recreation***'\n",
    "    mask_m1 = behav_act_df_7['Modifier_1'].notna()\n",
    "    mask_apply = mask_ex & mask_m1\n",
    "    if mask_apply.any():\n",
    "        mod1_norm = (\n",
    "            behav_act_df_7.loc[mask_apply, 'Modifier_1']\n",
    "            .astype(str).str.strip().str.lower()\n",
    "            .str.replace(r'/s+', '-', regex=True).str.replace('/', '-')\n",
    "        )\n",
    "        behav_act_df_7.loc[mask_apply, 'Activity_Type'] = 'EX-' + mod1_norm\n",
    "\n",
    "# work_type from Modifier_3\n",
    "work_labels = {'WRK- General**', 'WRK- Desk/Screen Based'}\n",
    "if 'Modifier_3' in behav_act_df_7.columns:\n",
    "    def _mk_work_type(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        raw = str(x).strip()\n",
    "        raw = re.sub(r'^/s*sp-/s*', '', raw, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"/s+\", '_', raw.lower()).replace('/', '_')\n",
    "        s = s.replace('hospiltality', 'hospitality')\n",
    "        return f\"work_{s}\" if s else np.nan\n",
    "    behav_act_df_7['work_type_raw'] = behav_act_df_7['Modifier_3'].apply(_mk_work_type)\n",
    "else:\n",
    "    behav_act_df_7['work_type_raw'] = np.nan\n",
    "\n",
    "# Expand Activity_Type to three encoded columns\n",
    "cols = ['activity_type', 'broad_domain', 'waves_domain']\n",
    "\n",
    "def _activity_meta_lookup(activity_type: object):\n",
    "    if isinstance(activity_type, str) and activity_type.startswith('EX-'):\n",
    "        return ('ex_sport', 'exercise', 'leisure')\n",
    "    return _activity_type_to_meta.get(activity_type)\n",
    "\n",
    "behav_act_df_7[cols] = behav_act_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "    lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    ")\n",
    "\n",
    "# Detect grouping\n",
    "if 'Observation' in behav_act_df_7.columns:\n",
    "    _group_cols = ['Observation']\n",
    "elif {'id','do'}.issubset(behav_act_df_7.columns):\n",
    "    _group_cols = ['id','do']\n",
    "else:\n",
    "    _group_cols = None\n",
    "\n",
    "# Forward-fill Activity_Type within observation\n",
    "if _group_cols is not None:\n",
    "    behav_act_df_7['Activity_Type'] = behav_act_df_7.groupby(_group_cols)['Activity_Type'].ffill()\n",
    "    behav_act_df_7[cols] = behav_act_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "        lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    "    )\n",
    "\n",
    "# Posture encoding\n",
    "def _map_posture_wbm_from_behavior(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('sb-sitting'):\n",
    "        return 'sitting'\n",
    "    if s.startswith('sb-lying') or s.startswith('sb- lying'):\n",
    "        return 'lying'\n",
    "    if s.startswith('la- kneeling'):\n",
    "        return 'kneel_squat'\n",
    "    if s == 'la- stretching':\n",
    "        return 'stretch'\n",
    "    if s == 'la- stand and move':\n",
    "        return 'stand_move'\n",
    "    if s == 'la- stand':\n",
    "        return 'stand'\n",
    "    if s in {'wa- walk', 'wa- walking', 'trav- walking', 'trav-walking'}:\n",
    "        return 'walk'\n",
    "    if s in {'wa-walk with load', 'wa- walk with load'}:\n",
    "        return 'walk_load'\n",
    "    if s == 'wa- ascend stairs':\n",
    "        return 'ascend'\n",
    "    if s == 'wa- descend stairs':\n",
    "        return 'descend'\n",
    "    if s == 'wa- running':\n",
    "        return 'running'\n",
    "    if s == 'sp- bike':\n",
    "        return 'biking'\n",
    "    if s in {'sp- other sport movement', 'sp- swing', 'sp -kick', 'sp- jump'}:\n",
    "        return 'sport_move'\n",
    "    if s == 'sp- muscle strengthening':\n",
    "        return 'muscle_strength'\n",
    "    if s == 'private/not coded':\n",
    "        return 'not_coded'\n",
    "    return None\n",
    "\n",
    "_posture_meta = {\n",
    "    'sitting': ('sedentary', 'sedentary'),\n",
    "    'lying': ('sedentary', 'sedentary'),\n",
    "    'kneel_squat': ('sedentary', 'mixed_move'),\n",
    "    'stretch': ('sport', 'sport'),\n",
    "    'stand': ('stand_move', 'mixed_move'),\n",
    "    'stand_move': ('stand_move', 'mixed_move'),\n",
    "    'walk': ('walk', 'walk'),\n",
    "    'walk_load': ('mod_walk', 'walk'),\n",
    "    'ascend': ('mod_walk', 'walk'),\n",
    "    'descend': ('mod_walk', 'walk'),\n",
    "    'running': ('running', 'running'),\n",
    "    'biking': ('biking', 'biking'),\n",
    "    'sport_move': ('sport', 'sport'),\n",
    "    'muscle_strength': ('sport', 'sport'),\n",
    "    'not_coded': ('not_coded', 'not_coded'),\n",
    "}\n",
    "\n",
    "# Build posture from Behavior_posture column (preserved from posture track)\n",
    "# CRITICAL: must use Behavior_posture, not merged Behavior, to avoid losing posture when both activity and posture exist at same second\n",
    "if 'Behavior_posture' in behav_act_df_7.columns:\n",
    "    behav_act_df_7['posture_wbm'] = behav_act_df_7['Behavior_posture'].apply(_map_posture_wbm_from_behavior)\n",
    "else:\n",
    "    # fallback: try to extract from merged Behavior (but this will miss simultaneous events)\n",
    "    behav_act_df_7['posture_wbm'] = behav_act_df_7['Behavior'].apply(\n",
    "        lambda b: _map_posture_wbm_from_behavior(b) if _classify_behavior(b) == 'posture' else None\n",
    "    )\n",
    "\n",
    "_broad_waves = behav_act_df_7['posture_wbm'].map(lambda k: _posture_meta.get(k, (np.nan, np.nan)))\n",
    "behav_act_df_7[['posture_broad', 'posture_waves']] = pd.DataFrame(_broad_waves.tolist(), index=behav_act_df_7.index)\n",
    "\n",
    "# Forward-fill posture within observation\n",
    "if _group_cols is not None:\n",
    "    for _c in ['posture_wbm', 'posture_broad', 'posture_waves']:\n",
    "        behav_act_df_7[_c] = behav_act_df_7.groupby(_group_cols)[_c].ffill()\n",
    "\n",
    "# waves_sedentary\n",
    "def _waves_sed_vec(posture_wbm, activity_type):\n",
    "    \"\"\"Vectorized waves_sedentary computation\"\"\"\n",
    "    result = pd.Series(index=posture_wbm.index, dtype='object')\n",
    "    \n",
    "    mask_sit = posture_wbm == 'sitting'\n",
    "    mask_drive = activity_type.isin({'trav_drive', 'trav_pass'})\n",
    "    result.loc[mask_sit & mask_drive] = 'sed_drive'\n",
    "    result.loc[mask_sit & ~mask_drive] = 'sedentary'\n",
    "    \n",
    "    mask_lying_kneel = posture_wbm.isin({'lying', 'kneel_squat'})\n",
    "    result.loc[mask_lying_kneel] = 'sedentary'\n",
    "    \n",
    "    mask_active = posture_wbm.notna() & ~mask_sit & ~mask_lying_kneel\n",
    "    result.loc[mask_active] = 'active'\n",
    "    \n",
    "    return result\n",
    "\n",
    "behav_act_df_7['waves_sedentary'] = _waves_sed_vec(behav_act_df_7['posture_wbm'], behav_act_df_7['activity_type'])\n",
    "\n",
    "# Intensity encoding\n",
    "# intensity typically comes from posture events (sb-, la-, wa-, sp-) so use Behavior_posture first\n",
    "def _posture_intensity(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('sb-sitting') or s.startswith('sb-lying') or s.startswith('sb- lying') or s.startswith('la- kneeling'):\n",
    "        return 'sedentary'\n",
    "    if s in {'la- stand', 'la- stand and move', 'la- stretching'}:\n",
    "        return 'light'\n",
    "    return None\n",
    "\n",
    "# try posture behavior first, then fall back to merged behavior\n",
    "if 'Behavior_posture' in behav_act_df_7.columns:\n",
    "    behav_act_df_7['intensity'] = behav_act_df_7['Behavior_posture'].apply(_posture_intensity)\n",
    "    # fill from activity behavior where posture didn't provide intensity\n",
    "    _mask_missing = behav_act_df_7['intensity'].isna()\n",
    "    behav_act_df_7.loc[_mask_missing, 'intensity'] = behav_act_df_7.loc[_mask_missing, 'Behavior_activity'].apply(_posture_intensity)\n",
    "else:\n",
    "    behav_act_df_7['intensity'] = behav_act_df_7['Behavior'].apply(_posture_intensity)\n",
    "\n",
    "# Fill from Modifier_2 only where intensity is still missing\n",
    "if 'Modifier_2' in behav_act_df_7.columns:\n",
    "    def _norm_intensity(m) -> str | None:\n",
    "        if pd.isna(m):\n",
    "            return None\n",
    "        s = str(m).strip().lower()\n",
    "        if not s:\n",
    "            return None\n",
    "        if s.startswith('vig'):\n",
    "            return 'vigorous'\n",
    "        if s.startswith('mod'):\n",
    "            return 'moderate'\n",
    "        if s == 'light':\n",
    "            return 'light'\n",
    "        if s == 'sedentary':\n",
    "            return 'sedentary'\n",
    "        return None\n",
    "    _mask_missing = behav_act_df_7['intensity'].isna()\n",
    "    behav_act_df_7.loc[_mask_missing, 'intensity'] = behav_act_df_7.loc[_mask_missing, 'Modifier_2'].apply(_norm_intensity)\n",
    "\n",
    "# Forward-fill intensity within observation\n",
    "if _group_cols is not None:\n",
    "    behav_act_df_7['intensity'] = behav_act_df_7.groupby(_group_cols)['intensity'].ffill()\n",
    "\n",
    "# waves_intensity\n",
    "behav_act_df_7['waves_intensity'] = behav_act_df_7['intensity'].map(lambda x: 'mvpa' if x in {'moderate', 'vigorous'} else x)\n",
    "\n",
    "# Finalize work_type\n",
    "if 'work_type_raw' in behav_act_df_7.columns:\n",
    "    if _group_cols is not None:\n",
    "        behav_act_df_7['work_type_raw'] = behav_act_df_7.groupby(_group_cols)['work_type_raw'].ffill()\n",
    "    behav_act_df_7['work_type'] = np.where(\n",
    "        behav_act_df_7['Activity_Type'].isin(work_labels),\n",
    "        behav_act_df_7['work_type_raw'],\n",
    "        np.nan,\n",
    "    )\n",
    "    behav_act_df_7 = behav_act_df_7.drop(columns=['work_type_raw'])\n",
    "\n",
    "# Drop non-codable\n",
    "_non_codable_mask = (\n",
    "    behav_act_df_7['Activity_Type'] == 'OTHER- Non-Codable (delete these rows from dataset)'\n",
    ") | (\n",
    "    behav_act_df_7['Behavior'].astype(str).str.strip().str.lower().isin(['private/not coded'])\n",
    ")\n",
    "behav_act_df_7 = behav_act_df_7.loc[~_non_codable_mask].copy()\n",
    "\n",
    "print(f\"After encoding, behav_act_df_7 shape: {behav_act_df_7.shape}\")\n",
    "print(f\"activity_type NaN: {behav_act_df_7['activity_type'].isna().sum()}\")\n",
    "print(f\"posture_wbm NaN: {behav_act_df_7['posture_wbm'].isna().sum()}\")\n",
    "\n",
    "# Stabilize both tracks with ffill+bfill\n",
    "if _group_cols is not None:\n",
    "    # Activity track\n",
    "    _before_act = behav_act_df_7['Activity_Type'].isna().sum()\n",
    "    ff_act = behav_act_df_7.groupby(_group_cols, sort=False)['Activity_Type'].ffill()\n",
    "    bf_act = behav_act_df_7.groupby(_group_cols, sort=False)['Activity_Type'].bfill()\n",
    "    behav_act_df_7['Activity_Type'] = ff_act.fillna(bf_act)\n",
    "    \n",
    "    # Recompute activity meta\n",
    "    behav_act_df_7[cols] = behav_act_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "        lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    "    )\n",
    "    _after_act = behav_act_df_7['Activity_Type'].isna().sum()\n",
    "    \n",
    "    # Posture track\n",
    "    _before_pos = behav_act_df_7['posture_wbm'].isna().sum()\n",
    "    ff_pos = behav_act_df_7.groupby(_group_cols, sort=False)['posture_wbm'].ffill()\n",
    "    bf_pos = behav_act_df_7.groupby(_group_cols, sort=False)['posture_wbm'].bfill()\n",
    "    behav_act_df_7['posture_wbm'] = ff_pos.fillna(bf_pos)\n",
    "    \n",
    "    # Recompute posture meta\n",
    "    _pw = behav_act_df_7['posture_wbm'].map(lambda k: _posture_meta.get(k, (np.nan, np.nan)))\n",
    "    behav_act_df_7[['posture_broad', 'posture_waves']] = pd.DataFrame(_pw.tolist(), index=behav_act_df_7.index)\n",
    "    _after_pos = behav_act_df_7['posture_wbm'].isna().sum()\n",
    "    \n",
    "    # Recompute waves_sedentary\n",
    "    behav_act_df_7['waves_sedentary'] = _waves_sed_vec(behav_act_df_7['posture_wbm'], behav_act_df_7['activity_type'])\n",
    "    \n",
    "    print(f\"Stabilization: activity_type {_before_act} -> {_after_act}, posture_wbm {_before_pos} -> {_after_pos}\")\n",
    "\n",
    "# Final cleanup: drop Behavior_activity and Behavior_posture now that encoding is complete\n",
    "for c in ['Behavior_activity', 'Behavior_posture']:\n",
    "    if c in behav_act_df_7.columns:\n",
    "        behav_act_df_7 = behav_act_df_7.drop(columns=c)\n",
    "\n",
    "# Build behav_copy for final output\n",
    "behav_copy = behav_act_df_7[[\"id\", \"do\", \"Time_Relative_hms_new\", 'activity_type', 'broad_domain', 'waves_domain', 'posture_wbm', 'posture_broad', 'posture_waves', 'waves_sedentary', \"intensity\", \"start_time_new\"]].copy()\n",
    "behav_copy = behav_copy.rename(columns={\"do\": \"obs\", \"Time_Relative_hms_new\": \"rel_time\"})\n",
    "behav_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab64ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined shape: (499132, 14)\n",
      "joined missing activity_type: 0\n",
      "joined missing posture: 0\n",
      "joined missing intensity: 1870\n",
      "/nsample:\n",
      "      id  obs       date         time              date_time  rel_time  \\\n",
      "100  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:40   \n",
      "101  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:41   \n",
      "102  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:42   \n",
      "103  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:43   \n",
      "104  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:44   \n",
      "105  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:45   \n",
      "106  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:46   \n",
      "107  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:47   \n",
      "108  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:48   \n",
      "109  102    1  7/24/2019  08:21:12 AM  7/24/2019 08:21:12 AM  00:01:49   \n",
      "\n",
      "    activity_type           broad_domain    waves_domain posture_wbm  \\\n",
      "100     trav_walk  active_transportation  transportation        walk   \n",
      "101     trav_walk  active_transportation  transportation     descend   \n",
      "102     trav_walk  active_transportation  transportation     descend   \n",
      "103     trav_walk  active_transportation  transportation     descend   \n",
      "104     trav_walk  active_transportation  transportation     descend   \n",
      "105     trav_walk  active_transportation  transportation     descend   \n",
      "106     trav_walk  active_transportation  transportation     descend   \n",
      "107     trav_walk  active_transportation  transportation     descend   \n",
      "108     trav_walk  active_transportation  transportation     descend   \n",
      "109     trav_walk  active_transportation  transportation     descend   \n",
      "\n",
      "    posture_broad posture_waves waves_sedentary intensity  \n",
      "100          walk          walk          active  moderate  \n",
      "101      mod_walk          walk          active  moderate  \n",
      "102      mod_walk          walk          active  moderate  \n",
      "103      mod_walk          walk          active  moderate  \n",
      "104      mod_walk          walk          active  moderate  \n",
      "105      mod_walk          walk          active  moderate  \n",
      "106      mod_walk          walk          active  moderate  \n",
      "107      mod_walk          walk          active  moderate  \n",
      "108      mod_walk          walk          active  moderate  \n",
      "109      mod_walk          walk          active  moderate  \n"
     ]
    }
   ],
   "source": [
    "# build final joined dataframe\n",
    "# cell 2 already stabilized activity_type and posture_wbm, so we just merge with log data\n",
    "\n",
    "joined = behav_copy.merge(\n",
    "    log_df2.loc[:, ['id', 'obs', 'date']],\n",
    "    on=['id', 'obs'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "joined = joined.rename(columns={'start_time_new': 'time'})\n",
    "joined = joined.copy()\n",
    "joined.loc[:, 'date_time'] = np.where(\n",
    "    joined['time'].notna(),\n",
    "    joined['date'].astype(str).str.strip() + ' ' + joined['time'].astype(str).str.strip(),\n",
    "    np.nan\n",
    ")\n",
    "joined = joined.loc[:, ['id', 'obs', 'date', 'time', 'date_time', 'rel_time', 'activity_type', 'broad_domain', 'waves_domain', 'posture_wbm', 'posture_broad', 'posture_waves', 'waves_sedentary', 'intensity']]\n",
    "\n",
    "print(f\"joined shape: {joined.shape}\")\n",
    "print(f\"joined missing activity_type: {joined['activity_type'].isna().sum()}\")\n",
    "print(f\"joined missing posture: {joined['posture_waves'].isna().sum()}\")\n",
    "print(f\"joined missing intensity: {(joined['intensity'].isna() | (joined['intensity'] == 'None')).sum()}\")\n",
    "print(\"/nsample:\")\n",
    "print(joined.iloc[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21664a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>date</th>\n",
       "      <th>date_time</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>broad_domain</th>\n",
       "      <th>waves_domain</th>\n",
       "      <th>posture_wbm</th>\n",
       "      <th>posture_broad</th>\n",
       "      <th>posture_waves</th>\n",
       "      <th>waves_sedentary</th>\n",
       "      <th>intensity</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>2019-07-24 08:21:12</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>2019-07-24 08:21:13</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>2019-07-24 08:21:14</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>2019-07-24 08:21:15</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>2019-07-24 08:21:16</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>stand_move</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>active</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  obs       date           date_time  rel_time activity_type  \\\n",
       "0  102    1  7/24/2019 2019-07-24 08:21:12  00:00:00  work_general   \n",
       "1  102    1  7/24/2019 2019-07-24 08:21:13  00:00:01  work_general   \n",
       "2  102    1  7/24/2019 2019-07-24 08:21:14  00:00:02  work_general   \n",
       "3  102    1  7/24/2019 2019-07-24 08:21:15  00:00:03  work_general   \n",
       "4  102    1  7/24/2019 2019-07-24 08:21:16  00:00:04  work_general   \n",
       "\n",
       "     broad_domain    waves_domain posture_wbm posture_broad posture_waves  \\\n",
       "0  work_education  work_education       stand    stand_move    mixed_move   \n",
       "1  work_education  work_education       stand    stand_move    mixed_move   \n",
       "2  work_education  work_education       stand    stand_move    mixed_move   \n",
       "3  work_education  work_education       stand    stand_move    mixed_move   \n",
       "4  work_education  work_education       stand    stand_move    mixed_move   \n",
       "\n",
       "  waves_sedentary intensity  Quality  Step  \n",
       "0          active     light      NaN   NaN  \n",
       "1          active     light  Codable   0.0  \n",
       "2          active     light  Codable   0.0  \n",
       "3          active     light  Codable   0.0  \n",
       "4          active     light  Codable   0.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add Steps\n",
    "steps_df = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/Data/seconds_ground_truth_20250410.csv\")\n",
    "steps_df = steps_df.rename(columns={\n",
    "    \"ID\" : \"id\",\n",
    "    \"Session\" : \"obs\",\n",
    "    \"relative_time_steps\" : \"rel_time\"\n",
    "})\n",
    "\n",
    "# stndardize rel_time\n",
    "def standardize_time(time_str):\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        hours = parts[0].zfill(2)  # Pad to 2 digits\n",
    "        return f\"{hours}:{parts[1]}:{parts[2]}\"\n",
    "    return time_str\n",
    "\n",
    "# Apply to both DataFrames before merging\n",
    "joined['rel_time'] = joined['rel_time'].apply(standardize_time)\n",
    "steps_df['rel_time'] = steps_df['rel_time'].apply(standardize_time)\n",
    "\n",
    "act_wstep_df = joined.merge(\n",
    "    steps_df[['id', 'obs', 'rel_time', 'Quality', 'Step']],\n",
    "    on=['id', 'obs', 'rel_time'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add rel_time to date_time to create absolute timestamp\n",
    "# Convert date_time to datetime\n",
    "act_wstep_df['date_time'] = pd.to_datetime(act_wstep_df['date_time'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "# Convert rel_time to timedelta (HH:MM:SS format)\n",
    "act_wstep_df['rel_time_timedelta'] = pd.to_timedelta(act_wstep_df['rel_time'])\n",
    "\n",
    "# Add rel_time to date_time and replace date_time with the result\n",
    "act_wstep_df['date_time'] = act_wstep_df['date_time'] + act_wstep_df['rel_time_timedelta']\n",
    "\n",
    "# Drop temporary column and time column\n",
    "act_wstep_df.drop(columns=[\"rel_time_timedelta\", \"time\"], inplace=True)\n",
    "\n",
    "act_wstep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd30565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported 509888 rows to Cameron_ACT24_Clean.csv\n",
      "columns: ['id', 'obs', 'date', 'date_time', 'rel_time', 'activity_type', 'broad_domain', 'waves_domain', 'posture_wbm', 'posture_broad', 'posture_waves', 'waves_sedentary', 'intensity', 'Quality', 'Step']\n"
     ]
    }
   ],
   "source": [
    "# export final cleaned dataframe to csv\n",
    "output_filename = 'Cameron_ACT24_Clean.csv'\n",
    "act_wstep_df.to_csv(output_filename, index=False)\n",
    "print(f\"exported {len(act_wstep_df)} rows to {output_filename}\")\n",
    "print(f\"columns: {list(act_wstep_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
