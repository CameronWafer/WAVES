{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664a7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d871038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HELIOS-300\\AppData\\Local\\Temp\\ipykernel_15704\\3939913406.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  act24_ground = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/Data/act24_prelim_groundtruth(in) (1).csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>observation</th>\n",
       "      <th>date</th>\n",
       "      <th>date_time</th>\n",
       "      <th>relative_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>broad_activity_type</th>\n",
       "      <th>work_type</th>\n",
       "      <th>posture</th>\n",
       "      <th>sedentary_not</th>\n",
       "      <th>walking_not</th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>quality</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 8:20</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>stand</td>\n",
       "      <td>not_sedentary</td>\n",
       "      <td>not_walking</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 8:20</td>\n",
       "      <td>0:00:01</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>stand</td>\n",
       "      <td>not_sedentary</td>\n",
       "      <td>not_walking</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 8:20</td>\n",
       "      <td>0:00:02</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>stand</td>\n",
       "      <td>not_sedentary</td>\n",
       "      <td>not_walking</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 8:20</td>\n",
       "      <td>0:00:03</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>stand</td>\n",
       "      <td>not_sedentary</td>\n",
       "      <td>not_walking</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 8:20</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>WRK- general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>SP- Education and Health Services</td>\n",
       "      <td>stand</td>\n",
       "      <td>not_sedentary</td>\n",
       "      <td>not_walking</td>\n",
       "      <td>light</td>\n",
       "      <td>Codable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  observation       date       date_time relative_time activity_type  \\\n",
       "0  102            1  7/24/2019  7/24/2019 8:20       0:00:00  WRK- general   \n",
       "1  102            1  7/24/2019  7/24/2019 8:20       0:00:01  WRK- general   \n",
       "2  102            1  7/24/2019  7/24/2019 8:20       0:00:02  WRK- general   \n",
       "3  102            1  7/24/2019  7/24/2019 8:20       0:00:03  WRK- general   \n",
       "4  102            1  7/24/2019  7/24/2019 8:20       0:00:04  WRK- general   \n",
       "\n",
       "  broad_activity_type                          work_type posture  \\\n",
       "0      work_education  SP- Education and Health Services   stand   \n",
       "1      work_education  SP- Education and Health Services   stand   \n",
       "2      work_education  SP- Education and Health Services   stand   \n",
       "3      work_education  SP- Education and Health Services   stand   \n",
       "4      work_education  SP- Education and Health Services   stand   \n",
       "\n",
       "   sedentary_not  walking_not activity_intensity  quality  step  \n",
       "0  not_sedentary  not_walking              light  Codable     0  \n",
       "1  not_sedentary  not_walking              light  Codable     0  \n",
       "2  not_sedentary  not_walking              light  Codable     0  \n",
       "3  not_sedentary  not_walking              light  Codable     0  \n",
       "4  not_sedentary  not_walking              light  Codable     0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act24_ground = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/Data/act24_prelim_groundtruth(in) (1).csv\")\n",
    "act24_ground.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3eaaf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HELIOS-300\\AppData\\Local\\Temp\\ipykernel_15704\\2165436145.py:1: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  act24_cam = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/WAVES/ACT24 Full Code/Cameron_ACT24_Clean.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>observation</th>\n",
       "      <th>date</th>\n",
       "      <th>date_time</th>\n",
       "      <th>relative_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>broad_activity_type</th>\n",
       "      <th>work_type</th>\n",
       "      <th>posture</th>\n",
       "      <th>activity_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 08:21:12 AM</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 08:21:12 AM</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 08:21:12 AM</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 08:21:12 AM</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>7/24/2019</td>\n",
       "      <td>7/24/2019 08:21:12 AM</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>work_general</td>\n",
       "      <td>work_education</td>\n",
       "      <td>work_education</td>\n",
       "      <td>stand</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  observation       date              date_time relative_time  \\\n",
       "0  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:00   \n",
       "1  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:01   \n",
       "2  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:02   \n",
       "3  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:03   \n",
       "4  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:04   \n",
       "\n",
       "  activity_type broad_activity_type       work_type posture activity_intensity  \n",
       "0  work_general      work_education  work_education   stand              light  \n",
       "1  work_general      work_education  work_education   stand              light  \n",
       "2  work_general      work_education  work_education   stand              light  \n",
       "3  work_general      work_education  work_education   stand              light  \n",
       "4  work_general      work_education  work_education   stand              light  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act24_cam = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/WAVES/ACT24 Full Code/Cameron_ACT24_Clean.csv\")\n",
    "act24_cam = act24_cam[[\"id\", \"obs\", \"date\", \"date_time\", \"rel_time\", \"activity_type\", \"broad_domain\", \"waves_domain\", \"posture_wbm\", \"intensity\"]]\n",
    "\n",
    "act24_cam = act24_cam.rename(columns={\n",
    "    \"obs\" : \"observation\",\n",
    "    \"rel_time\" : \"relative_time\",\n",
    "    \"broad_domain\" : \"broad_activity_type\",\n",
    "    \"waves_domain\" : \"work_type\",\n",
    "    \"posture_wbm\" : \"posture\",\n",
    "    \"intensity\" : \"activity_intensity\"\n",
    "})\n",
    "\n",
    "act24_cam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb0356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground shape:  (401689, 14)\n",
      "cam shape:  (460935, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"ground shape: \", act24_ground.shape)\n",
    "print(\"cam shape: \", act24_cam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbb1ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE COMPARISON: act24_ground vs act24_cam\n",
      "================================================================================\n",
      "\n",
      "Common columns to compare (7): ['activity_intensity', 'activity_type', 'broad_activity_type', 'date', 'date_time', 'posture', 'work_type']\n",
      "Merge keys: ['id', 'observation', 'relative_time']\n",
      "\n",
      "Unique keys in ground: 401,689\n",
      "Unique keys in cam: 415,556\n",
      "Overlapping keys (rows in both): 335,157\n",
      "\n",
      "================================================================================\n",
      "COLUMN-BY-COLUMN COMPARISON\n",
      "================================================================================\n",
      "\n",
      "work_type:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 0 (0.00%)\n",
      "  Mismatches: 367,487 (100.00%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=1, time=00:00:00\n",
      "      Ground: SP- Education and Health Services\n",
      "      Cam: work_education\n",
      "    id=102, obs=1, time=00:00:01\n",
      "      Ground: SP- Education and Health Services\n",
      "      Cam: work_education\n",
      "    id=102, obs=1, time=00:00:02\n",
      "      Ground: SP- Education and Health Services\n",
      "      Cam: work_education\n",
      "    id=102, obs=1, time=00:00:03\n",
      "      Ground: SP- Education and Health Services\n",
      "      Cam: work_education\n",
      "    id=102, obs=1, time=00:00:04\n",
      "      Ground: SP- Education and Health Services\n",
      "      Cam: work_education\n",
      "  Values only in ground (5): ['SP- Trade, Retail, Transportation, and Utilities', 'Other', 'SP- Education and Health Services', 'SP- Leisure and Hospiltality', 'SP- Office (business, professional services, finance, info)']\n",
      "  Values only in cam (5): ['household_personal', 'work_education', 'leisure', 'transportation', 'purchase_other']\n",
      "\n",
      "date_time:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 0 (0.00%)\n",
      "  Mismatches: 367,487 (100.00%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=1, time=00:00:00\n",
      "      Ground: 7/24/2019 8:20\n",
      "      Cam: 7/24/2019 08:21:12 AM\n",
      "    id=102, obs=1, time=00:00:01\n",
      "      Ground: 7/24/2019 8:20\n",
      "      Cam: 7/24/2019 08:21:12 AM\n",
      "    id=102, obs=1, time=00:00:02\n",
      "      Ground: 7/24/2019 8:20\n",
      "      Cam: 7/24/2019 08:21:12 AM\n",
      "    id=102, obs=1, time=00:00:03\n",
      "      Ground: 7/24/2019 8:20\n",
      "      Cam: 7/24/2019 08:21:12 AM\n",
      "    id=102, obs=1, time=00:00:04\n",
      "      Ground: 7/24/2019 8:20\n",
      "      Cam: 7/24/2019 08:21:12 AM\n",
      "  Values only in ground (5683): ['9/7/2019 10:55', '7/24/2019 8:52', '10/19/2019 15:07', '8/20/2019 8:31', '10/11/2019 10:56']\n",
      "  Values only in cam (626): ['9/9/2019 11:16:13 AM', '11/10/2019 10:28:41 AM', '10/15/2019 03:32:01 PM', '9/12/2019 11:24:26 AM', '9/10/2019 08:28:07 AM']\n",
      "\n",
      "broad_activity_type:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 222,559 (60.56%)\n",
      "  Mismatches: 144,928 (39.44%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=1, time=00:09:49\n",
      "      Ground: purchasing\n",
      "      Cam: purchase_other\n",
      "    id=102, obs=1, time=00:09:50\n",
      "      Ground: purchasing\n",
      "      Cam: purchase_other\n",
      "    id=102, obs=1, time=00:09:51\n",
      "      Ground: purchasing\n",
      "      Cam: purchase_other\n",
      "    id=102, obs=1, time=00:09:52\n",
      "      Ground: purchasing\n",
      "      Cam: purchase_other\n",
      "    id=102, obs=1, time=00:09:53\n",
      "      Ground: purchasing\n",
      "      Cam: purchase_other\n",
      "  Values only in ground (3): ['household_personal', 'purchasing', 'transportation']\n",
      "  Values only in cam (7): ['sleep', 'Trav_car', 'personal', 'Leisure_Screen', 'maintenance_repair']\n",
      "\n",
      "posture:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 277,799 (75.59%)\n",
      "  Mismatches: 89,688 (24.41%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=1, time=00:00:59\n",
      "      Ground: descend stairs\n",
      "      Cam: descend\n",
      "    id=102, obs=1, time=00:01:00\n",
      "      Ground: descend stairs\n",
      "      Cam: descend\n",
      "    id=102, obs=1, time=00:01:01\n",
      "      Ground: descend stairs\n",
      "      Cam: descend\n",
      "    id=102, obs=1, time=00:01:02\n",
      "      Ground: descend stairs\n",
      "      Cam: descend\n",
      "    id=102, obs=1, time=00:01:03\n",
      "      Ground: descend stairs\n",
      "      Cam: descend\n",
      "  Values only in ground (9): ['stretching', 'muscle strengthening', 'other sport movement', 'stand and move', 'kneeling/ squatting']\n",
      "  Values only in cam (9): ['descend', 'muscle_strength', 'stand_move', 'biking', 'ascend']\n",
      "\n",
      "date:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 367,487 (100.00%)\n",
      "  Mismatches: 0 (0.00%)\n",
      "\n",
      "activity_type:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 0 (0.00%)\n",
      "  Mismatches: 367,487 (100.00%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=1, time=00:00:00\n",
      "      Ground: WRK- general\n",
      "      Cam: work_general\n",
      "    id=102, obs=1, time=00:00:01\n",
      "      Ground: WRK- general\n",
      "      Cam: work_general\n",
      "    id=102, obs=1, time=00:00:02\n",
      "      Ground: WRK- general\n",
      "      Cam: work_general\n",
      "    id=102, obs=1, time=00:00:03\n",
      "      Ground: WRK- general\n",
      "      Cam: work_general\n",
      "    id=102, obs=1, time=00:00:04\n",
      "      Ground: WRK- general\n",
      "      Cam: work_general\n",
      "  Values only in ground (29): ['EX- hiking', 'EX- other', 'EX- jogging', 'ORG- volunteer', 'TRAV- passenger (car/truck/motorcycle)']\n",
      "  Values only in cam (24): ['trav_pass', 'sleep', 'com_volunteer', 'com_purchase', 'ha_housework']\n",
      "\n",
      "activity_intensity:\n",
      "  Rows compared: 367,487\n",
      "  Exact matches: 335,156 (91.20%)\n",
      "  Mismatches: 32,331 (8.80%)\n",
      "  Sample mismatches:\n",
      "    id=102, obs=2, time=02:15:05\n",
      "      Ground: moderate\n",
      "      Cam: light\n",
      "    id=102, obs=2, time=02:15:06\n",
      "      Ground: moderate\n",
      "      Cam: light\n",
      "    id=102, obs=2, time=02:15:07\n",
      "      Ground: moderate\n",
      "      Cam: light\n",
      "    id=102, obs=2, time=02:17:36\n",
      "      Ground: moderate\n",
      "      Cam: light\n",
      "    id=102, obs=2, time=02:17:37\n",
      "      Ground: moderate\n",
      "      Cam: light\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "================================================================================\n",
      "             column  rows_compared  exact_matches  match_percentage  mismatches  mismatch_percentage\n",
      "          work_type         367487              0          0.000000      367487           100.000000\n",
      "          date_time         367487              0          0.000000      367487           100.000000\n",
      "broad_activity_type         367487         222559         60.562414      144928            39.437586\n",
      "            posture         367487         277799         75.594239       89688            24.405761\n",
      "               date         367487         367487        100.000000           0             0.000000\n",
      "      activity_type         367487              0          0.000000      367487           100.000000\n",
      " activity_intensity         367487         335156         91.202138       32331             8.797862\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE COMPARISON OF SECOND-BY-SECOND DATA\n",
    "# These are second-by-second files where each row represents one second\n",
    "# Merge key: id + observation + relative_time (should be unique for each second)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE COMPARISON: act24_ground vs act24_cam\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find common columns to compare\n",
    "common_cols = set(act24_ground.columns) & set(act24_cam.columns)\n",
    "merge_keys = ['id', 'observation', 'relative_time']\n",
    "compare_cols = [c for c in common_cols if c not in merge_keys]\n",
    "\n",
    "print(f\"\\nCommon columns to compare ({len(compare_cols)}): {sorted(compare_cols)}\")\n",
    "print(f\"Merge keys: {merge_keys}\")\n",
    "\n",
    "# Normalize relative_time format for comparison (handle potential format differences)\n",
    "# Convert relative_time to consistent format (HH:MM:SS)\n",
    "def normalize_time(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    time_str = str(time_str).strip()\n",
    "    # Handle formats like \"0:00:00\", \"00:00:00\", \"0:00:25.01\", etc.\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        # Handle decimal seconds (e.g., \"25.01\" -> \"25\") by converting to float then int\n",
    "        seconds_part = str(int(float(parts[2])))\n",
    "        return f\"{int(parts[0]):02d}:{int(parts[1]):02d}:{seconds_part.zfill(2)}\"\n",
    "    return time_str\n",
    "\n",
    "act24_ground['_rel_time_norm'] = act24_ground['relative_time'].apply(normalize_time)\n",
    "act24_cam['_rel_time_norm'] = act24_cam['relative_time'].apply(normalize_time)\n",
    "\n",
    "# Create composite merge key: id|observation|relative_time\n",
    "act24_ground['_merge_key'] = (\n",
    "    act24_ground['id'].astype(str) + '|' + \n",
    "    act24_ground['observation'].astype(str) + '|' + \n",
    "    act24_ground['_rel_time_norm'].astype(str)\n",
    ")\n",
    "act24_cam['_merge_key'] = (\n",
    "    act24_cam['id'].astype(str) + '|' + \n",
    "    act24_cam['observation'].astype(str) + '|' + \n",
    "    act24_cam['_rel_time_norm'].astype(str)\n",
    ")\n",
    "\n",
    "# Find overlapping keys\n",
    "ground_keys = set(act24_ground['_merge_key'].dropna())\n",
    "cam_keys = set(act24_cam['_merge_key'].dropna())\n",
    "common_keys = ground_keys & cam_keys\n",
    "\n",
    "print(f\"\\nUnique keys in ground: {len(ground_keys):,}\")\n",
    "print(f\"Unique keys in cam: {len(cam_keys):,}\")\n",
    "print(f\"Overlapping keys (rows in both): {len(common_keys):,}\")\n",
    "\n",
    "# Compare each common column\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"COLUMN-BY-COLUMN COMPARISON\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for col in compare_cols:\n",
    "    if col not in act24_ground.columns or col not in act24_cam.columns:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    \n",
    "    # Filter to common keys and merge\n",
    "    ground_subset = act24_ground[act24_ground['_merge_key'].isin(common_keys)][['_merge_key', col]].copy()\n",
    "    cam_subset = act24_cam[act24_cam['_merge_key'].isin(common_keys)][['_merge_key', col]].copy()\n",
    "    \n",
    "    # Merge on the key\n",
    "    merged = ground_subset.merge(\n",
    "        cam_subset,\n",
    "        on='_merge_key',\n",
    "        how='inner',\n",
    "        suffixes=('_ground', '_cam')\n",
    "    )\n",
    "    \n",
    "    if len(merged) > 0:\n",
    "        # Compare values\n",
    "        merged['_match'] = (merged[f'{col}_ground'].astype(str) == merged[f'{col}_cam'].astype(str))\n",
    "        match_count = merged['_match'].sum()\n",
    "        mismatch_count = (~merged['_match']).sum()\n",
    "        match_pct = (match_count / len(merged)) * 100\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'column': col,\n",
    "            'rows_compared': len(merged),\n",
    "            'exact_matches': match_count,\n",
    "            'match_percentage': match_pct,\n",
    "            'mismatches': mismatch_count,\n",
    "            'mismatch_percentage': 100 - match_pct\n",
    "        })\n",
    "        \n",
    "        print(f\"  Rows compared: {len(merged):,}\")\n",
    "        print(f\"  Exact matches: {match_count:,} ({match_pct:.2f}%)\")\n",
    "        print(f\"  Mismatches: {mismatch_count:,} ({100-match_pct:.2f}%)\")\n",
    "        \n",
    "        # Show sample mismatches\n",
    "        if mismatch_count > 0:\n",
    "            mismatches = merged[~merged['_match']].head(5)\n",
    "            print(f\"  Sample mismatches:\")\n",
    "            for idx, row in mismatches.iterrows():\n",
    "                key_parts = row['_merge_key'].split('|')\n",
    "                print(f\"    id={key_parts[0]}, obs={key_parts[1]}, time={key_parts[2]}\")\n",
    "                print(f\"      Ground: {row[f'{col}_ground']}\")\n",
    "                print(f\"      Cam: {row[f'{col}_cam']}\")\n",
    "        \n",
    "        # Value distribution comparison\n",
    "        ground_vals = set(merged[f'{col}_ground'].dropna().astype(str))\n",
    "        cam_vals = set(merged[f'{col}_cam'].dropna().astype(str))\n",
    "        only_ground = ground_vals - cam_vals\n",
    "        only_cam = cam_vals - ground_vals\n",
    "        \n",
    "        if len(only_ground) > 0:\n",
    "            print(f\"  Values only in ground ({len(only_ground)}): {list(only_ground)[:5]}\")\n",
    "        if len(only_cam) > 0:\n",
    "            print(f\"  Values only in cam ({len(only_cam)}): {list(only_cam)[:5]}\")\n",
    "    else:\n",
    "        print(f\"  No overlapping rows to compare\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "act24_ground.drop(columns=['_rel_time_norm', '_merge_key'], inplace=True, errors='ignore')\n",
    "act24_cam.drop(columns=['_rel_time_norm', '_merge_key'], inplace=True, errors='ignore')\n",
    "\n",
    "# Summary\n",
    "if comparison_results:\n",
    "    comparison_summary = pd.DataFrame(comparison_results)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(comparison_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08eb109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE ROW COUNT DIFFERENCES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "OVERVIEW:\n",
      "  act24_ground total rows: 401,689\n",
      "  act24_cam total rows: 460,935\n",
      "  Absolute difference: 59,246 rows\n",
      "  Percentage difference: 14.75%\n",
      "  → act24_cam has 59,246 MORE rows than act24_ground\n",
      "\n",
      "================================================================================\n",
      "KEY OVERLAP ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Each row is uniquely identified by: id + observation + relative_time\n",
      "\n",
      "Unique row identifiers (keys):\n",
      "  Total unique keys in ground: 401,689\n",
      "  Total unique keys in cam: 415,556\n",
      "  Keys present in BOTH dataframes: 335,157 (80.7% of larger dataset)\n",
      "  Keys ONLY in ground: 66,532 (16.6% of ground)\n",
      "  Keys ONLY in cam: 80,399 (19.3% of cam)\n",
      "\n",
      "Interpretation:\n",
      "  • 335,157 seconds are recorded in BOTH datasets (can be compared)\n",
      "  • 66,532 seconds exist ONLY in ground dataset (missing from cam)\n",
      "  • 80,399 seconds exist ONLY in cam dataset (missing from ground)\n",
      "  • Net difference: 13,867 more unique seconds in cam\n",
      "\n",
      "================================================================================\n",
      "DETAILED BREAKDOWN BY ID AND OBSERVATION\n",
      "================================================================================\n",
      "\n",
      "Unique (id, observation) combinations:\n",
      "  In ground: 40 combinations\n",
      "  In cam: 48 combinations\n",
      "  In both: 40 combinations\n",
      "  Only in ground: 0 combinations\n",
      "  Only in cam: 8 combinations\n",
      "\n",
      "================================================================================\n",
      "ALL (ID, OBSERVATION) COMBINATIONS - COMPLETE LIST\n",
      "================================================================================\n",
      "\n",
      "Showing ALL 48 combinations, sorted by absolute difference:\n",
      " id  observation  ground_count  cam_count  difference  percent_diff\n",
      "134            2             0      10726       10726        100.00\n",
      "154            1             0      10615       10615        100.00\n",
      "139            1             0      10584       10584        100.00\n",
      "126            1             0      10394       10394        100.00\n",
      "136            2             0      10364       10364        100.00\n",
      "154            2         10312        136      -10176        -98.68\n",
      "131            2             0      10107       10107        100.00\n",
      "138            2             0       9925        9925        100.00\n",
      "139            2             0       7458        7458        100.00\n",
      "124            1         10769       6634       -4135        -38.40\n",
      "127            1          9767       5758       -4009        -41.05\n",
      "122            1          5967       9342        3375         36.13\n",
      "117            1         10700       7965       -2735        -25.56\n",
      "150            1          9717      12174        2457         20.18\n",
      "128            1          9085       6941       -2144        -23.60\n",
      "138            1          4304       6385        2081         32.59\n",
      "127            2         10530       9479       -1051         -9.98\n",
      "130            2         10678       9894        -784         -7.34\n",
      "102            2         10733      10018        -715         -6.66\n",
      "124            2         10801      10104        -697         -6.45\n",
      "144            2          8764       8170        -594         -6.78\n",
      "135            2         10671      10085        -586         -5.49\n",
      "126            2         10792      10357        -435         -4.03\n",
      "150            2         10724      10356        -368         -3.43\n",
      "130            1         10384      10619         235          2.21\n",
      "140            1          9403       9181        -222         -2.36\n",
      "135            1         10556      10736         180          1.68\n",
      "141            1          9554       9384        -170         -1.78\n",
      "132            1         10240      10099        -141         -1.38\n",
      "129            1         10785      10658        -127         -1.18\n",
      "117            2         10876      10781         -95         -0.87\n",
      "143            1         10692      10612         -80         -0.75\n",
      "133            1         10391      10444          53          0.51\n",
      "116            1         10606      10559         -47         -0.44\n",
      "134            1          9746       9707         -39         -0.40\n",
      "122            2         10776      10814          38          0.35\n",
      "143            2         10672      10700          28          0.26\n",
      "128            2         10561      10535         -26         -0.25\n",
      "133            2         10348      10361          13          0.13\n",
      "132            2          9723       9712         -11         -0.11\n",
      "131            1         10649      10654           5          0.05\n",
      "116            2          7597       7592          -5         -0.07\n",
      "102            1         10759      10760           1          0.01\n",
      "136            1         10430      10429          -1         -0.01\n",
      "129            2         10805      10805           0          0.00\n",
      "140            2         10686      10686           0          0.00\n",
      "141            2         10396      10396           0          0.00\n",
      "144            1         10740      10740           0          0.00\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Combinations where cam has MORE rows:\n",
      "  Count: 19 combinations\n",
      "  Total extra rows: 88,639\n",
      "  Average extra rows per combination: 4665.2\n",
      "  Median extra rows: 2457\n",
      "  Max extra rows: 10,726\n",
      "\n",
      "Combinations where ground has MORE rows:\n",
      "  Count: 25 combinations\n",
      "  Total extra rows: 29,393\n",
      "  Average extra rows per combination: 1175.7\n",
      "  Median extra rows: 368\n",
      "  Max extra rows: 10,176\n",
      "\n",
      "Combinations with EQUAL row counts:\n",
      "  Count: 4 combinations\n",
      "\n",
      "================================================================================\n",
      "ROWS ONLY IN GROUND - DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total rows only in ground: 66,532\n",
      "\n",
      "Breakdown by (id, observation) - ALL combinations:\n",
      " id  observation  count\n",
      "135            1  10555\n",
      "154            2  10311\n",
      "143            2   7515\n",
      "141            1   5158\n",
      "127            1   4181\n",
      "124            1   4163\n",
      "128            1   3859\n",
      "117            1   3010\n",
      "129            1   2814\n",
      "144            2   1589\n",
      "122            1   1478\n",
      "116            1   1326\n",
      "140            1   1185\n",
      "134            1   1183\n",
      "127            2   1111\n",
      "136            1    869\n",
      "130            2    784\n",
      "116            2    733\n",
      "102            2    715\n",
      "124            2    697\n",
      "135            2    590\n",
      "132            1    582\n",
      "128            2    476\n",
      "126            2    444\n",
      "150            2    377\n",
      "143            1    311\n",
      "122            2    246\n",
      "117            2     95\n",
      "130            1     95\n",
      "132            2     68\n",
      "150            1     12\n",
      "\n",
      "Breakdown by date:\n",
      "      date  count\n",
      "10/15/2019  10555\n",
      " 2/23/2020  10311\n",
      "11/16/2019   7515\n",
      " 8/28/2019   5641\n",
      " 11/6/2019   5158\n",
      " 8/20/2019   4336\n",
      "  9/6/2019   4303\n",
      "  9/5/2019   4181\n",
      "  9/7/2019   2814\n",
      "11/23/2019   1589\n",
      " 9/10/2019   1260\n",
      " 11/9/2019   1185\n",
      " 10/9/2019   1183\n",
      "  9/9/2019   1111\n",
      " 8/29/2019    943\n",
      "10/17/2019    869\n",
      " 8/21/2019    828\n",
      " 7/25/2019    715\n",
      "10/19/2019    590\n",
      " 10/4/2019    582\n",
      " 1/21/2020    377\n",
      "11/18/2019    311\n",
      "  9/8/2019     95\n",
      "10/10/2019     68\n",
      " 1/19/2020     12\n",
      "\n",
      "Sample rows (first 20, showing full context):\n",
      " id  observation      date relative_time     activity_type posture activity_intensity\n",
      "102            2 7/25/2019       2:47:58 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:47:59 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:00 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:01 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:02 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:03 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:04 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:05 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:06 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:07 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:08 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:09 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:10 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:11 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:12 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:13 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:14 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:15 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:16 WRK- screen based sitting          sedentary\n",
      "102            2 7/25/2019       2:48:17 WRK- screen based sitting          sedentary\n",
      "\n",
      "Time distribution for rows only in ground:\n",
      "  Min time: 0 seconds (0:00:00)\n",
      "  Max time: 13737 seconds (3:48:57)\n",
      "  Mean time: 7771 seconds (2:09:30)\n",
      "  Median time: 8616 seconds (2:23:35)\n",
      "\n",
      "================================================================================\n",
      "ROWS ONLY IN CAM - DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total rows only in cam: 93,448\n",
      "\n",
      "Breakdown by (id, observation) - ALL combinations:\n",
      " id  observation  count\n",
      "134            2  10726\n",
      "154            1  10615\n",
      "139            1  10584\n",
      "126            1  10394\n",
      "136            2  10364\n",
      "131            2  10107\n",
      "138            2   9925\n",
      "139            2   7458\n",
      "122            1   4853\n",
      "150            1   2469\n",
      "138            1   2081\n",
      "128            1   1715\n",
      "144            2    995\n",
      "130            1    330\n",
      "127            1    172\n",
      "143            1    109\n",
      "132            1     78\n",
      "117            1     77\n",
      "127            2     60\n",
      "116            2     57\n",
      "143            2     54\n",
      "133            1     53\n",
      "122            2     51\n",
      "124            1     28\n",
      "140            1     21\n",
      "136            1     19\n",
      "116            1     16\n",
      "133            2     13\n",
      "126            2      9\n",
      "150            2      9\n",
      "131            1      5\n",
      "102            1      1\n",
      "\n",
      "Breakdown by date:\n",
      "      date  count\n",
      "10/13/2019  10726\n",
      " 2/22/2020  10615\n",
      " 11/3/2019  10584\n",
      "  9/2/2019  10394\n",
      "10/19/2019  10364\n",
      " 9/16/2019  10107\n",
      " 11/2/2019   9925\n",
      " 11/5/2019   7458\n",
      " 8/28/2019   4881\n",
      " 1/19/2020   2469\n",
      " 11/1/2019   2081\n",
      "  9/6/2019   1724\n",
      "11/23/2019    995\n",
      "  9/8/2019    330\n",
      "  9/5/2019    172\n",
      "11/18/2019    109\n",
      " 8/20/2019     93\n",
      " 10/4/2019     78\n",
      "  9/9/2019     60\n",
      " 8/21/2019     57\n",
      "11/16/2019     54\n",
      "10/10/2019     53\n",
      " 8/29/2019     51\n",
      " 11/9/2019     21\n",
      "10/17/2019     19\n",
      "10/11/2019     13\n",
      " 1/21/2020      9\n",
      " 9/12/2019      5\n",
      " 7/24/2019      1\n",
      "\n",
      "Sample rows (first 20, showing full context):\n",
      " id  observation      date relative_time activity_type    posture activity_intensity\n",
      "102            1 7/24/2019      02:22:08  work_general       walk           moderate\n",
      "116            1 8/20/2019      00:00:00  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:01  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:02  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:03  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:04  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:05  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:06  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:07  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:08  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:09  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:10  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:11  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:12  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:13  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:14  work_general stand_move                NaN\n",
      "116            1 8/20/2019      00:00:15  work_general stand_move                NaN\n",
      "116            2 8/21/2019      00:38:16   work_screen    sitting          sedentary\n",
      "116            2 8/21/2019      00:38:17   work_screen    sitting          sedentary\n",
      "116            2 8/21/2019      00:38:18   work_screen    sitting          sedentary\n",
      "\n",
      "Time distribution for rows only in cam:\n",
      "  Min time: 0 seconds (0:00:00)\n",
      "  Max time: 10798 seconds (2:59:58)\n",
      "  Mean time: 4591 seconds (1:16:30)\n",
      "  Median time: 4087 seconds (1:08:07)\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY AND INTERPRETATION\n",
      "================================================================================\n",
      "\n",
      "Key Findings:\n",
      "  1. Row count difference: 59,246 rows (14.7%)\n",
      "  2. Overlapping data: 335,157 seconds appear in both datasets\n",
      "  3. Missing from cam: 66,532 seconds in ground are not in cam\n",
      "  4. Missing from ground: 80,399 seconds in cam are not in ground\n",
      "  5. Unique combinations: 8 (id, obs) pairs exist only in cam\n",
      "  6. Unique combinations: 0 (id, obs) pairs exist only in ground\n",
      "\n",
      "This suggests:\n",
      "  • Different data collection/processing methods may have included/excluded certain time periods\n",
      "  • Some (id, observation) combinations may have been processed differently\n",
      "  • Time range differences may indicate different start/end times or filtering criteria\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE ANALYSIS: ROWS THAT EXIST IN ONE DATAFRAME BUT NOT THE OTHER\n",
    "# This analysis explains why the dataframes have different row counts and provides\n",
    "# detailed breakdowns to understand the differences\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE ROW COUNT DIFFERENCES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nOVERVIEW:\")\n",
    "print(f\"  act24_ground total rows: {len(act24_ground):,}\")\n",
    "print(f\"  act24_cam total rows: {len(act24_cam):,}\")\n",
    "print(f\"  Absolute difference: {abs(len(act24_cam) - len(act24_ground)):,} rows\")\n",
    "print(f\"  Percentage difference: {abs(len(act24_cam) - len(act24_ground)) / len(act24_ground) * 100:.2f}%\")\n",
    "if len(act24_cam) > len(act24_ground):\n",
    "    print(f\"  → act24_cam has {len(act24_cam) - len(act24_ground):,} MORE rows than act24_ground\")\n",
    "else:\n",
    "    print(f\"  → act24_ground has {len(act24_ground) - len(act24_cam):,} MORE rows than act24_cam\")\n",
    "\n",
    "# Helper functions\n",
    "def normalize_time(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    time_str = str(time_str).strip()\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        seconds_part = str(int(float(parts[2])))\n",
    "        return f\"{int(parts[0]):02d}:{int(parts[1]):02d}:{seconds_part.zfill(2)}\"\n",
    "    return time_str\n",
    "\n",
    "def time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    time_str = str(time_str).strip()\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(float(parts[2]))\n",
    "    return None\n",
    "\n",
    "act24_ground['_rel_time_norm'] = act24_ground['relative_time'].apply(normalize_time)\n",
    "act24_cam['_rel_time_norm'] = act24_cam['relative_time'].apply(normalize_time)\n",
    "\n",
    "act24_ground['_merge_key'] = (\n",
    "    act24_ground['id'].astype(str) + '|' + \n",
    "    act24_ground['observation'].astype(str) + '|' + \n",
    "    act24_ground['_rel_time_norm'].astype(str)\n",
    ")\n",
    "act24_cam['_merge_key'] = (\n",
    "    act24_cam['id'].astype(str) + '|' + \n",
    "    act24_cam['observation'].astype(str) + '|' + \n",
    "    act24_cam['_rel_time_norm'].astype(str)\n",
    ")\n",
    "\n",
    "# Find keys in each dataframe\n",
    "ground_keys = set(act24_ground['_merge_key'].dropna())\n",
    "cam_keys = set(act24_cam['_merge_key'].dropna())\n",
    "common_keys = ground_keys & cam_keys\n",
    "only_ground = ground_keys - cam_keys\n",
    "only_cam = cam_keys - ground_keys\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"KEY OVERLAP ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nEach row is uniquely identified by: id + observation + relative_time\")\n",
    "print(f\"\\nUnique row identifiers (keys):\")\n",
    "print(f\"  Total unique keys in ground: {len(ground_keys):,}\")\n",
    "print(f\"  Total unique keys in cam: {len(cam_keys):,}\")\n",
    "print(f\"  Keys present in BOTH dataframes: {len(common_keys):,} ({len(common_keys)/max(len(ground_keys), len(cam_keys))*100:.1f}% of larger dataset)\")\n",
    "print(f\"  Keys ONLY in ground: {len(only_ground):,} ({len(only_ground)/len(ground_keys)*100:.1f}% of ground)\")\n",
    "print(f\"  Keys ONLY in cam: {len(only_cam):,} ({len(only_cam)/len(cam_keys)*100:.1f}% of cam)\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  • {len(common_keys):,} seconds are recorded in BOTH datasets (can be compared)\")\n",
    "print(f\"  • {len(only_ground):,} seconds exist ONLY in ground dataset (missing from cam)\")\n",
    "print(f\"  • {len(only_cam):,} seconds exist ONLY in cam dataset (missing from ground)\")\n",
    "print(f\"  • Net difference: {len(only_cam) - len(only_ground):,} more unique seconds in cam\")\n",
    "\n",
    "# Analyze which id/observation combinations have differences\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DETAILED BREAKDOWN BY ID AND OBSERVATION\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Get unique id/observation combinations\n",
    "ground_id_obs = act24_ground[['id', 'observation']].drop_duplicates()\n",
    "cam_id_obs = act24_cam[['id', 'observation']].drop_duplicates()\n",
    "\n",
    "print(f\"\\nUnique (id, observation) combinations:\")\n",
    "print(f\"  In ground: {len(ground_id_obs)} combinations\")\n",
    "print(f\"  In cam: {len(cam_id_obs)} combinations\")\n",
    "print(f\"  In both: {len(set(zip(ground_id_obs['id'], ground_id_obs['observation'])) & set(zip(cam_id_obs['id'], cam_id_obs['observation'])))} combinations\")\n",
    "only_ground_combos = set(zip(ground_id_obs['id'], ground_id_obs['observation'])) - set(zip(cam_id_obs['id'], cam_id_obs['observation']))\n",
    "only_cam_combos = set(zip(cam_id_obs['id'], cam_id_obs['observation'])) - set(zip(ground_id_obs['id'], ground_id_obs['observation']))\n",
    "print(f\"  Only in ground: {len(only_ground_combos)} combinations\")\n",
    "print(f\"  Only in cam: {len(only_cam_combos)} combinations\")\n",
    "\n",
    "# Count rows per id/observation\n",
    "ground_counts = act24_ground.groupby(['id', 'observation']).size().reset_index(name='ground_count')\n",
    "cam_counts = act24_cam.groupby(['id', 'observation']).size().reset_index(name='cam_count')\n",
    "\n",
    "# Merge to compare\n",
    "counts_merged = ground_counts.merge(\n",
    "    cam_counts,\n",
    "    on=['id', 'observation'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 (for combinations that only exist in one dataframe)\n",
    "counts_merged['ground_count'] = counts_merged['ground_count'].fillna(0).astype(int)\n",
    "counts_merged['cam_count'] = counts_merged['cam_count'].fillna(0).astype(int)\n",
    "counts_merged['difference'] = counts_merged['cam_count'] - counts_merged['ground_count']\n",
    "counts_merged['abs_difference'] = counts_merged['difference'].abs()\n",
    "counts_merged['percent_diff'] = (counts_merged['difference'] / counts_merged[['ground_count', 'cam_count']].max(axis=1) * 100).round(2)\n",
    "\n",
    "# Sort by absolute difference\n",
    "counts_merged_sorted = counts_merged.sort_values('abs_difference', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ALL (ID, OBSERVATION) COMBINATIONS - COMPLETE LIST\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nShowing ALL {len(counts_merged)} combinations, sorted by absolute difference:\")\n",
    "print(counts_merged_sorted[['id', 'observation', 'ground_count', 'cam_count', 'difference', 'percent_diff']].to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "cam_more = counts_merged[counts_merged['difference'] > 0]\n",
    "ground_more = counts_merged[counts_merged['difference'] < 0]\n",
    "equal = counts_merged[counts_merged['difference'] == 0]\n",
    "\n",
    "print(f\"\\nCombinations where cam has MORE rows:\")\n",
    "print(f\"  Count: {len(cam_more)} combinations\")\n",
    "print(f\"  Total extra rows: {cam_more['difference'].sum():,}\")\n",
    "print(f\"  Average extra rows per combination: {cam_more['difference'].mean():.1f}\")\n",
    "print(f\"  Median extra rows: {cam_more['difference'].median():.0f}\")\n",
    "print(f\"  Max extra rows: {cam_more['difference'].max():,}\")\n",
    "\n",
    "print(f\"\\nCombinations where ground has MORE rows:\")\n",
    "print(f\"  Count: {len(ground_more)} combinations\")\n",
    "print(f\"  Total extra rows: {abs(ground_more['difference'].sum()):,}\")\n",
    "print(f\"  Average extra rows per combination: {abs(ground_more['difference']).mean():.1f}\")\n",
    "print(f\"  Median extra rows: {abs(ground_more['difference']).median():.0f}\")\n",
    "print(f\"  Max extra rows: {abs(ground_more['difference']).max():,}\")\n",
    "\n",
    "print(f\"\\nCombinations with EQUAL row counts:\")\n",
    "print(f\"  Count: {len(equal)} combinations\")\n",
    "\n",
    "# Detailed breakdown of rows only in ground\n",
    "if len(only_ground) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ROWS ONLY IN GROUND - DETAILED ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    ground_only_df = act24_ground[act24_ground['_merge_key'].isin(only_ground)].copy()\n",
    "    \n",
    "    print(f\"\\nTotal rows only in ground: {len(ground_only_df):,}\")\n",
    "    \n",
    "    # Breakdown by id/observation\n",
    "    print(f\"\\nBreakdown by (id, observation) - ALL combinations:\")\n",
    "    ground_only_by_id = ground_only_df.groupby(['id', 'observation']).size().reset_index(name='count')\n",
    "    ground_only_by_id = ground_only_by_id.sort_values('count', ascending=False)\n",
    "    print(ground_only_by_id.to_string(index=False))\n",
    "    \n",
    "    # Breakdown by date\n",
    "    print(f\"\\nBreakdown by date:\")\n",
    "    ground_only_by_date = ground_only_df.groupby('date').size().reset_index(name='count')\n",
    "    ground_only_by_date = ground_only_by_date.sort_values('count', ascending=False)\n",
    "    print(ground_only_by_date.to_string(index=False))\n",
    "    \n",
    "    # Sample rows with more context\n",
    "    print(f\"\\nSample rows (first 20, showing full context):\")\n",
    "    sample_ground = ground_only_df.head(20)\n",
    "    print(sample_ground[['id', 'observation', 'date', 'relative_time', 'activity_type', 'posture', 'activity_intensity']].to_string(index=False))\n",
    "    \n",
    "    # Time distribution\n",
    "    ground_only_times = ground_only_df['relative_time'].apply(time_to_seconds)\n",
    "    print(f\"\\nTime distribution for rows only in ground:\")\n",
    "    print(f\"  Min time: {ground_only_times.min()} seconds ({ground_only_times.min() // 3600}:{(ground_only_times.min() % 3600) // 60:02d}:{ground_only_times.min() % 60:02d})\")\n",
    "    print(f\"  Max time: {ground_only_times.max()} seconds ({ground_only_times.max() // 3600}:{(ground_only_times.max() % 3600) // 60:02d}:{ground_only_times.max() % 60:02d})\")\n",
    "    print(f\"  Mean time: {ground_only_times.mean():.0f} seconds ({int(ground_only_times.mean()) // 3600}:{(int(ground_only_times.mean()) % 3600) // 60:02d}:{int(ground_only_times.mean()) % 60:02d})\")\n",
    "    print(f\"  Median time: {ground_only_times.median():.0f} seconds ({int(ground_only_times.median()) // 3600}:{(int(ground_only_times.median()) % 3600) // 60:02d}:{int(ground_only_times.median()) % 60:02d})\")\n",
    "\n",
    "# Detailed breakdown of rows only in cam\n",
    "if len(only_cam) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ROWS ONLY IN CAM - DETAILED ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    cam_only_df = act24_cam[act24_cam['_merge_key'].isin(only_cam)].copy()\n",
    "    \n",
    "    print(f\"\\nTotal rows only in cam: {len(cam_only_df):,}\")\n",
    "    \n",
    "    # Breakdown by id/observation\n",
    "    print(f\"\\nBreakdown by (id, observation) - ALL combinations:\")\n",
    "    cam_only_by_id = cam_only_df.groupby(['id', 'observation']).size().reset_index(name='count')\n",
    "    cam_only_by_id = cam_only_by_id.sort_values('count', ascending=False)\n",
    "    print(cam_only_by_id.to_string(index=False))\n",
    "    \n",
    "    # Breakdown by date\n",
    "    print(f\"\\nBreakdown by date:\")\n",
    "    cam_only_by_date = cam_only_df.groupby('date').size().reset_index(name='count')\n",
    "    cam_only_by_date = cam_only_by_date.sort_values('count', ascending=False)\n",
    "    print(cam_only_by_date.to_string(index=False))\n",
    "    \n",
    "    # Sample rows with more context\n",
    "    print(f\"\\nSample rows (first 20, showing full context):\")\n",
    "    sample_cam = cam_only_df.head(20)\n",
    "    print(sample_cam[['id', 'observation', 'date', 'relative_time', 'activity_type', 'posture', 'activity_intensity']].to_string(index=False))\n",
    "    \n",
    "    # Time distribution\n",
    "    cam_only_times = cam_only_df['relative_time'].apply(time_to_seconds)\n",
    "    print(f\"\\nTime distribution for rows only in cam:\")\n",
    "    print(f\"  Min time: {cam_only_times.min()} seconds ({cam_only_times.min() // 3600}:{(cam_only_times.min() % 3600) // 60:02d}:{cam_only_times.min() % 60:02d})\")\n",
    "    print(f\"  Max time: {cam_only_times.max()} seconds ({cam_only_times.max() // 3600}:{(cam_only_times.max() % 3600) // 60:02d}:{cam_only_times.max() % 60:02d})\")\n",
    "    print(f\"  Mean time: {cam_only_times.mean():.0f} seconds ({int(cam_only_times.mean()) // 3600}:{(int(cam_only_times.mean()) % 3600) // 60:02d}:{int(cam_only_times.mean()) % 60:02d})\")\n",
    "    print(f\"  Median time: {cam_only_times.median():.0f} seconds ({int(cam_only_times.median()) // 3600}:{(int(cam_only_times.median()) % 3600) // 60:02d}:{int(cam_only_times.median()) % 60:02d})\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL SUMMARY AND INTERPRETATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  1. Row count difference: {len(act24_cam) - len(act24_ground):,} rows ({abs(len(act24_cam) - len(act24_ground)) / len(act24_ground) * 100:.1f}%)\")\n",
    "print(f\"  2. Overlapping data: {len(common_keys):,} seconds appear in both datasets\")\n",
    "print(f\"  3. Missing from cam: {len(only_ground):,} seconds in ground are not in cam\")\n",
    "print(f\"  4. Missing from ground: {len(only_cam):,} seconds in cam are not in ground\")\n",
    "print(f\"  5. Unique combinations: {len(only_cam_combos)} (id, obs) pairs exist only in cam\")\n",
    "print(f\"  6. Unique combinations: {len(only_ground_combos)} (id, obs) pairs exist only in ground\")\n",
    "print(f\"\\nThis suggests:\")\n",
    "print(f\"  • Different data collection/processing methods may have included/excluded certain time periods\")\n",
    "print(f\"  • Some (id, observation) combinations may have been processed differently\")\n",
    "print(f\"  • Time range differences may indicate different start/end times or filtering criteria\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "act24_ground.drop(columns=['_rel_time_norm', '_merge_key'], inplace=True, errors='ignore')\n",
    "act24_cam.drop(columns=['_rel_time_norm', '_merge_key'], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb1d92ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ACT24_CAM DATAFRAME EXPLORATION\n",
      "============================================================\n",
      "\n",
      "Shape: (460935, 10)\n",
      "\n",
      "Column names (10):\n",
      "['id', 'observation', 'date', 'date_time', 'relative_time', 'activity_type', 'broad_activity_type', 'work_type', 'posture', 'activity_intensity']\n",
      "\n",
      "Data types:\n",
      "id                      int64\n",
      "observation             int64\n",
      "date                   object\n",
      "date_time              object\n",
      "relative_time          object\n",
      "activity_type          object\n",
      "broad_activity_type    object\n",
      "work_type              object\n",
      "posture                object\n",
      "activity_intensity     object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "    id  observation       date              date_time relative_time  \\\n",
      "0  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:00   \n",
      "1  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:01   \n",
      "2  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:02   \n",
      "3  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:03   \n",
      "4  102            1  7/24/2019  7/24/2019 08:21:12 AM      00:00:04   \n",
      "\n",
      "  activity_type broad_activity_type       work_type posture activity_intensity  \n",
      "0  work_general      work_education  work_education   stand              light  \n",
      "1  work_general      work_education  work_education   stand              light  \n",
      "2  work_general      work_education  work_education   stand              light  \n",
      "3  work_general      work_education  work_education   stand              light  \n",
      "4  work_general      work_education  work_education   stand              light  \n",
      "\n",
      "Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 460935 entries, 0 to 460934\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   id                   460935 non-null  int64 \n",
      " 1   observation          460935 non-null  int64 \n",
      " 2   date                 460935 non-null  object\n",
      " 3   date_time            460935 non-null  object\n",
      " 4   relative_time        460935 non-null  object\n",
      " 5   activity_type        460935 non-null  object\n",
      " 6   broad_activity_type  460935 non-null  object\n",
      " 7   work_type            460935 non-null  object\n",
      " 8   posture              460935 non-null  object\n",
      " 9   activity_intensity   459065 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 35.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test1 = act24_ground[act24_ground[\"id\"] == 154]\n",
    "test1 = act24_ground[act24_ground[\"observation\"] == 2]\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfdb4001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FOCUSED REPORT: MISSING (ID, OBSERVATION) PAIRS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total (ID, Observation) pairs in ground: 40\n",
      "Total (ID, Observation) pairs in cam: 48\n",
      "Pairs in BOTH datasets: 40\n",
      "Pairs ONLY in ground: 0\n",
      "Pairs ONLY in cam: 8\n",
      "\n",
      "================================================================================\n",
      "(ID, OBSERVATION) PAIRS ONLY IN GROUND TRUTH\n",
      "================================================================================\n",
      "None - All pairs in ground truth are also in cam dataset\n",
      "\n",
      "================================================================================\n",
      "(ID, OBSERVATION) PAIRS ONLY IN CAM DATASET\n",
      "================================================================================\n",
      "\n",
      "8 pair(s) missing from ground truth:\n",
      "\n",
      "  ID 126, Observation 1: 10,394 rows | Date: 9/2/2019\n",
      "  ID 131, Observation 2: 10,107 rows | Date: 9/16/2019\n",
      "  ID 134, Observation 2: 10,726 rows | Date: 10/13/2019\n",
      "  ID 136, Observation 2: 10,364 rows | Date: 10/19/2019\n",
      "  ID 138, Observation 2:  9,925 rows | Date: 11/2/2019\n",
      "  ID 139, Observation 1: 10,584 rows | Date: 11/3/2019\n",
      "  ID 139, Observation 2:  7,458 rows | Date: 11/5/2019\n",
      "  ID 154, Observation 1: 10,615 rows | Date: 2/22/2020\n",
      "\n",
      "================================================================================\n",
      "COMPLETE (ID, OBSERVATION) PAIR COMPARISON TABLE\n",
      "================================================================================\n",
      "\n",
      " ID  Observation In Ground In Cam  Ground Rows  Cam Rows  Difference   Status\n",
      "102            1       Yes    Yes        10759     10760           1     Both\n",
      "102            2       Yes    Yes        10733     10018        -715     Both\n",
      "116            1       Yes    Yes        10606     10559         -47     Both\n",
      "116            2       Yes    Yes         7597      7592          -5     Both\n",
      "117            1       Yes    Yes        10700      7965       -2735     Both\n",
      "117            2       Yes    Yes        10876     10781         -95     Both\n",
      "122            1       Yes    Yes         5967      9342        3375     Both\n",
      "122            2       Yes    Yes        10776     10814          38     Both\n",
      "124            1       Yes    Yes        10769      6634       -4135     Both\n",
      "124            2       Yes    Yes        10801     10104        -697     Both\n",
      "126            1        No    Yes            0     10394       10394 Cam only\n",
      "126            2       Yes    Yes        10792     10357        -435     Both\n",
      "127            1       Yes    Yes         9767      5758       -4009     Both\n",
      "127            2       Yes    Yes        10530      9479       -1051     Both\n",
      "128            1       Yes    Yes         9085      6941       -2144     Both\n",
      "128            2       Yes    Yes        10561     10535         -26     Both\n",
      "129            1       Yes    Yes        10785     10658        -127     Both\n",
      "129            2       Yes    Yes        10805     10805           0     Both\n",
      "130            1       Yes    Yes        10384     10619         235     Both\n",
      "130            2       Yes    Yes        10678      9894        -784     Both\n",
      "131            1       Yes    Yes        10649     10654           5     Both\n",
      "131            2        No    Yes            0     10107       10107 Cam only\n",
      "132            1       Yes    Yes        10240     10099        -141     Both\n",
      "132            2       Yes    Yes         9723      9712         -11     Both\n",
      "133            1       Yes    Yes        10391     10444          53     Both\n",
      "133            2       Yes    Yes        10348     10361          13     Both\n",
      "134            1       Yes    Yes         9746      9707         -39     Both\n",
      "134            2        No    Yes            0     10726       10726 Cam only\n",
      "135            1       Yes    Yes        10556     10736         180     Both\n",
      "135            2       Yes    Yes        10671     10085        -586     Both\n",
      "136            1       Yes    Yes        10430     10429          -1     Both\n",
      "136            2        No    Yes            0     10364       10364 Cam only\n",
      "138            1       Yes    Yes         4304      6385        2081     Both\n",
      "138            2        No    Yes            0      9925        9925 Cam only\n",
      "139            1        No    Yes            0     10584       10584 Cam only\n",
      "139            2        No    Yes            0      7458        7458 Cam only\n",
      "140            1       Yes    Yes         9403      9181        -222     Both\n",
      "140            2       Yes    Yes        10686     10686           0     Both\n",
      "141            1       Yes    Yes         9554      9384        -170     Both\n",
      "141            2       Yes    Yes        10396     10396           0     Both\n",
      "143            1       Yes    Yes        10692     10612         -80     Both\n",
      "143            2       Yes    Yes        10672     10700          28     Both\n",
      "144            1       Yes    Yes        10740     10740           0     Both\n",
      "144            2       Yes    Yes         8764      8170        -594     Both\n",
      "150            1       Yes    Yes         9717     12174        2457     Both\n",
      "150            2       Yes    Yes        10724     10356        -368     Both\n",
      "154            1        No    Yes            0     10615       10615 Cam only\n",
      "154            2       Yes    Yes        10312       136      -10176     Both\n",
      "\n",
      "================================================================================\n",
      "KEY FINDINGS\n",
      "================================================================================\n",
      "• 0 (ID, Observation) pair(s) exist in ground truth but NOT in your cam dataset\n",
      "• 8 (ID, Observation) pair(s) exist in your cam dataset but NOT in ground truth\n",
      "• 40 (ID, Observation) pair(s) exist in both datasets\n",
      "⚠️  Your cam dataset includes 8 observation(s) not in ground truth\n"
     ]
    }
   ],
   "source": [
    "# FOCUSED REPORT: (ID, OBSERVATION) PAIRS IN ONE DATASET BUT NOT THE OTHER\n",
    "print(\"=\" * 80)\n",
    "print(\"FOCUSED REPORT: MISSING (ID, OBSERVATION) PAIRS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get all unique (id, observation) combinations\n",
    "ground_id_obs = act24_ground[['id', 'observation']].drop_duplicates()\n",
    "cam_id_obs = act24_cam[['id', 'observation']].drop_duplicates()\n",
    "\n",
    "ground_combos = set(zip(ground_id_obs['id'], ground_id_obs['observation']))\n",
    "cam_combos = set(zip(cam_id_obs['id'], cam_id_obs['observation']))\n",
    "common_combos = ground_combos & cam_combos\n",
    "only_ground_combos = ground_combos - cam_combos\n",
    "only_cam_combos = cam_combos - ground_combos\n",
    "\n",
    "# Get row counts for context\n",
    "ground_counts = act24_ground.groupby(['id', 'observation']).size().reset_index(name='count')\n",
    "cam_counts = act24_cam.groupby(['id', 'observation']).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total (ID, Observation) pairs in ground: {len(ground_combos)}\")\n",
    "print(f\"Total (ID, Observation) pairs in cam: {len(cam_combos)}\")\n",
    "print(f\"Pairs in BOTH datasets: {len(common_combos)}\")\n",
    "print(f\"Pairs ONLY in ground: {len(only_ground_combos)}\")\n",
    "print(f\"Pairs ONLY in cam: {len(only_cam_combos)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"(ID, OBSERVATION) PAIRS ONLY IN GROUND TRUTH\")\n",
    "print(\"=\" * 80)\n",
    "if len(only_ground_combos) == 0:\n",
    "    print(\"None - All pairs in ground truth are also in cam dataset\")\n",
    "else:\n",
    "    only_ground_sorted = sorted(only_ground_combos)\n",
    "    print(f\"\\n{len(only_ground_combos)} pair(s) missing from cam dataset:\\n\")\n",
    "    for id_val, obs_val in only_ground_sorted:\n",
    "        count = ground_counts[(ground_counts['id'] == id_val) & (ground_counts['observation'] == obs_val)]['count'].values[0]\n",
    "        date_info = act24_ground[(act24_ground['id'] == id_val) & (act24_ground['observation'] == obs_val)]['date'].iloc[0] if len(act24_ground[(act24_ground['id'] == id_val) & (act24_ground['observation'] == obs_val)]) > 0 else \"N/A\"\n",
    "        print(f\"  ID {id_val:3d}, Observation {obs_val:1d}: {count:6,} rows | Date: {date_info}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"(ID, OBSERVATION) PAIRS ONLY IN CAM DATASET\")\n",
    "print(\"=\" * 80)\n",
    "if len(only_cam_combos) == 0:\n",
    "    print(\"None - All pairs in cam dataset are also in ground truth\")\n",
    "else:\n",
    "    only_cam_sorted = sorted(only_cam_combos)\n",
    "    print(f\"\\n{len(only_cam_combos)} pair(s) missing from ground truth:\\n\")\n",
    "    for id_val, obs_val in only_cam_sorted:\n",
    "        count = cam_counts[(cam_counts['id'] == id_val) & (cam_counts['observation'] == obs_val)]['count'].values[0]\n",
    "        date_info = act24_cam[(act24_cam['id'] == id_val) & (act24_cam['observation'] == obs_val)]['date'].iloc[0] if len(act24_cam[(act24_cam['id'] == id_val) & (act24_cam['observation'] == obs_val)]) > 0 else \"N/A\"\n",
    "        print(f\"  ID {id_val:3d}, Observation {obs_val:1d}: {count:6,} rows | Date: {date_info}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLETE (ID, OBSERVATION) PAIR COMPARISON TABLE\")\n",
    "print(\"=\" * 80)\n",
    "# Create comprehensive comparison table\n",
    "all_combos = ground_combos | cam_combos\n",
    "comparison_data = []\n",
    "for id_val, obs_val in sorted(all_combos):\n",
    "    in_ground = (id_val, obs_val) in ground_combos\n",
    "    in_cam = (id_val, obs_val) in cam_combos\n",
    "    \n",
    "    ground_count = ground_counts[(ground_counts['id'] == id_val) & (ground_counts['observation'] == obs_val)]['count'].values[0] if in_ground else 0\n",
    "    cam_count = cam_counts[(cam_counts['id'] == id_val) & (cam_counts['observation'] == obs_val)]['count'].values[0] if in_cam else 0\n",
    "    \n",
    "    status = \"Both\" if (in_ground and in_cam) else (\"Ground only\" if in_ground else \"Cam only\")\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'ID': id_val,\n",
    "        'Observation': obs_val,\n",
    "        'In Ground': 'Yes' if in_ground else 'No',\n",
    "        'In Cam': 'Yes' if in_cam else 'No',\n",
    "        'Ground Rows': ground_count,\n",
    "        'Cam Rows': cam_count,\n",
    "        'Difference': cam_count - ground_count,\n",
    "        'Status': status\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"• {len(only_ground_combos)} (ID, Observation) pair(s) exist in ground truth but NOT in your cam dataset\")\n",
    "print(f\"• {len(only_cam_combos)} (ID, Observation) pair(s) exist in your cam dataset but NOT in ground truth\")\n",
    "print(f\"• {len(common_combos)} (ID, Observation) pair(s) exist in both datasets\")\n",
    "if len(only_ground_combos) > 0:\n",
    "    print(f\"\\n⚠️  Your cam dataset is missing {len(only_ground_combos)} observation(s) from ground truth\")\n",
    "if len(only_cam_combos) > 0:\n",
    "    print(f\"⚠️  Your cam dataset includes {len(only_cam_combos)} observation(s) not in ground truth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e98fe2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229561, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = act24_cam[act24_cam[\"id\"] == 154]\n",
    "test2 = act24_cam[act24_cam[\"observation\"] == 2]\n",
    "test2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
