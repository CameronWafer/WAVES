{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3294cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258328d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>type</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_day</th>\n",
       "      <th>start_year</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>session</th>\n",
       "      <th>do</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DO2</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>18:44:45</td>\n",
       "      <td>20:47:00</td>\n",
       "      <td>2:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DO1</td>\n",
       "      <td>H</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>16:43:57</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>2:01:03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DO1</td>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>13:17:10</td>\n",
       "      <td>15:17:32</td>\n",
       "      <td>2:00:22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>DO2_a</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>8:00:27</td>\n",
       "      <td>8:52:32</td>\n",
       "      <td>0:52:05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>DO2_b</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>8:56:13</td>\n",
       "      <td>10:12:29</td>\n",
       "      <td>1:16:16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    obs type  start_month  start_day  start_year start_time stop_time  \\\n",
       "0   1    DO2    L           10          3        2017   18:44:45  20:47:00   \n",
       "1   1    DO1    H           10          6        2017   16:43:57  18:45:00   \n",
       "2   2    DO1    H            7         24        2017   13:17:10  15:17:32   \n",
       "3   2  DO2_a    A            7         25        2017    8:00:27   8:52:32   \n",
       "4   2  DO2_b    A            7         25        2017    8:56:13  10:12:29   \n",
       "\n",
       "  duration  session  do  \n",
       "0  2:02:15        1   1  \n",
       "1  2:01:03        2   2  \n",
       "2  2:00:22        1   1  \n",
       "3  0:52:05        2   2  \n",
       "4  1:16:16        3   3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AM import (both log and behavior)\n",
    "behav_am_df = pd.read_excel(\"C:/Users/HELIOS-300/Desktop/Data/am_behposture_onesheet.xlsx\", engine='openpyxl')\n",
    "log_df = pd.read_csv(\"C:/Users/HELIOS-300/Desktop/Data/DO_LOG_final.csv\", encoding='utf-8')\n",
    "\n",
    "behav_am_df = behav_am_df[behav_am_df[\"Event_Type\"] == \"State start\"]\n",
    "\n",
    "# Convert timedelta columns back to time strings (HH:MM:SS format)\n",
    "# This fixes the \"0 days 00:00:00\" display issue\n",
    "for col in behav_am_df.columns:\n",
    "    if pd.api.types.is_timedelta64_dtype(behav_am_df[col]):\n",
    "        # Convert timedelta to time string by adding to a base date and extracting time\n",
    "        base_date = pd.Timestamp('1900-01-01')\n",
    "        behav_am_df[col] = (base_date + behav_am_df[col]).dt.strftime('%H:%M:%S')\n",
    "\n",
    "# special log AM setup / cleanup\n",
    "# Extract ID from id column (e.g., \"AM02\" -> 2)\n",
    "log_df['id'] = log_df[\"id\"].astype(str)\n",
    "log_df['id'] = log_df['id'].str.extract(r'AM(\\d{2})', expand=False)\n",
    "log_df['id'] = pd.to_numeric(log_df[\"id\"], errors=\"coerce\").astype(np.int64)\n",
    "\n",
    "log_df[\"do\"] = log_df[\"session\"]\n",
    "\n",
    "# special behav AM setup / cleanup\n",
    "# Extract ID from Observation column (e.g., \"AM02DO1_J_FINAL_R\" -> 2)\n",
    "behav_am_df['id'] = behav_am_df['Observation'].str.extract(r'AM(\\d{2})', expand=False).astype(np.int64)\n",
    "# Extract DO from Observation column (e.g., \"AM02DO1_J_FINAL_R\" -> 1)\n",
    "behav_am_df['do'] = behav_am_df['Observation'].str.extract(r'DO(\\d+)', expand=False).astype(np.int64)\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2ce9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>type</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_day</th>\n",
       "      <th>start_year</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>session</th>\n",
       "      <th>do</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DO2</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>18:44:45</td>\n",
       "      <td>20:47:00</td>\n",
       "      <td>2:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DO1</td>\n",
       "      <td>H</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>16:43:57</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>2:01:03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DO1</td>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>13:17:10</td>\n",
       "      <td>15:17:32</td>\n",
       "      <td>2:00:22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>DO2_a</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>8:00:27</td>\n",
       "      <td>8:52:32</td>\n",
       "      <td>0:52:05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>DO2_b</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>8:56:13</td>\n",
       "      <td>10:12:29</td>\n",
       "      <td>1:16:16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    obs type  start_month  start_day  start_year start_time stop_time  \\\n",
       "0   1    DO2    L           10          3        2017   18:44:45  20:47:00   \n",
       "1   1    DO1    H           10          6        2017   16:43:57  18:45:00   \n",
       "2   2    DO1    H            7         24        2017   13:17:10  15:17:32   \n",
       "3   2  DO2_a    A            7         25        2017    8:00:27   8:52:32   \n",
       "4   2  DO2_b    A            7         25        2017    8:56:13  10:12:29   \n",
       "\n",
       "  duration  session  do  \n",
       "0  2:02:15        1   1  \n",
       "1  2:01:03        2   2  \n",
       "2  2:00:22        1   1  \n",
       "3  0:52:05        2   2  \n",
       "4  1:16:16        3   3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad82c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity events: 731, Posture events: 9678, Other: 103\n",
      "Activity expanded: 996552, Posture expanded: 857325\n",
      "Merged result: 1184000 rows\n",
      "After encoding, behav_am_df_7 shape: (1177432, 23)\n",
      "activity_type NaN: 81524\n",
      "posture_wbm NaN: 516\n",
      "Stabilization: activity_type 81524 -> 0, posture_wbm 516 -> 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>date_time</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>posture_waves</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  obs       date         time              date_time  rel_time  \\\n",
       "0  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:00   \n",
       "1  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:01   \n",
       "2  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:02   \n",
       "3  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:03   \n",
       "4  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:04   \n",
       "\n",
       "  activity_type posture_waves intensity  \n",
       "0    les_social    mixed_move     light  \n",
       "1    les_social    mixed_move     light  \n",
       "2    les_social    mixed_move     light  \n",
       "3    les_social    mixed_move     light  \n",
       "4    les_social    mixed_move     light  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Behavior AM data cleaning\n",
    "# Separates activity and posture tracks to preserve simultaneous events at same timestamp\n",
    "\n",
    "# quick log data cleaning\n",
    "log_df['date'] = pd.to_datetime({\n",
    "    'year': pd.to_numeric(log_df['start_year'], errors='coerce'),\n",
    "    'month': pd.to_numeric(log_df['start_month'], errors='coerce'),\n",
    "    'day': pd.to_numeric(log_df['start_day'], errors='coerce'),\n",
    "}, errors='coerce').dt.strftime('%#m/%#d/%Y')\n",
    "\n",
    "log_df.drop(columns=[\"start_month\", \"start_day\", \"start_year\"], inplace=True)\n",
    "log_df2 = log_df.loc[:, [\"id\", \"do\", \"date\", \"start_time\"]].copy()\n",
    "\n",
    "# Convert log_df2 start_time to 24-hour HH:MM:SS\n",
    "s = log_df2['start_time'].astype(str).str.strip()\n",
    "\n",
    "# Support both with and without seconds\n",
    "_dt1 = pd.to_datetime(s, format='%I:%M:%S %p', errors='coerce')\n",
    "_dt2 = pd.to_datetime(s, format='%I:%M %p', errors='coerce')\n",
    "\n",
    "log_df2.loc[:, 'start_time'] = _dt1.fillna(_dt2).dt.strftime('%H:%M:%S')\n",
    "log_df2.loc[:, 'date_time'] = log_df2['date'].astype(str).str.strip() + ' ' + log_df2['start_time'].astype(str).str.strip()\n",
    "\n",
    "log_df2.rename(columns={\"start_time\" : \"time\", \"do\" : \"obs\"}, inplace=True)\n",
    "log_df2 = log_df2.drop(columns=[\"time\", \"date_time\"])\n",
    "\n",
    "\n",
    "# Start behavior cleaning\n",
    "# a) why does unnamed 17 and 18 exist? no one knows :)\n",
    "behav_am_df1 = behav_am_df.drop(columns=[\"Date_Time_Absolute_dmy_hmsf\", \n",
    "\"Date_dmy\", \n",
    "\"Time_Absolute_hms\", \n",
    "\"Time_Absolute_f\",\n",
    "\"Event_Log\"])\n",
    "\n",
    "# add \"id\" and \"do\" style ID's from LOG into ACT behavior file so we can join\n",
    "def add_id_do_split(df, source_col='Observation', id_col='id', do_col='do', inplace=True):\n",
    "    parts = df[source_col].str.split('_', expand=True)\n",
    "    id_series = pd.to_numeric(parts[1], errors='coerce').astype('Int64')\n",
    "    do_series = pd.to_numeric(parts[2], errors='coerce').astype('Int64')\n",
    "    if inplace:\n",
    "        df[id_col] = id_series\n",
    "        df[do_col] = do_series\n",
    "        return df\n",
    "    out = df.copy()\n",
    "    out[id_col] = id_series\n",
    "    out[do_col] = do_series\n",
    "    return out\n",
    "\n",
    "# add a column from LOG onto Behavior based on \"id\" and \"do\"\n",
    "def add_col_from_other_df_merge(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    left_keys: list,\n",
    "    right_keys: list,\n",
    "    right_value_col: str,\n",
    "    new_col_name: str | None = None,\n",
    "    how: str = 'left',\n",
    "    validate: str = 'many_to_one'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a single column from `right` to `left` by joining on two (or more) key columns.\n",
    "    \"\"\"\n",
    "    if new_col_name is None:\n",
    "        new_col_name = right_value_col\n",
    "\n",
    "    right_subset = right[right_keys + [right_value_col]].rename(\n",
    "        columns={right_value_col: new_col_name}\n",
    "    )\n",
    "    merged = left.merge(\n",
    "        right_subset,\n",
    "        how=how,\n",
    "        left_on=left_keys,\n",
    "        right_on=right_keys,\n",
    "        validate=validate\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "# Merge with log_df on 'id' and 'do' to get 'start_time'\n",
    "# Note: 'do' is already extracted from Observation column in cell 1, so we merge on both keys\n",
    "behav_am_df2 = behav_am_df1.copy()\n",
    "\n",
    "# Ensure 'do' column exists before merge (safety check)\n",
    "if 'do' not in behav_am_df2.columns:\n",
    "    behav_am_df2['do'] = behav_am_df2['Observation'].str.extract(r'DO(\\d+)', expand=False).astype(np.int64)\n",
    "\n",
    "behav_am_df3 = behav_am_df2.merge(\n",
    "    log_df[['id', 'session', 'start_time', 'date']].rename(columns={'session': 'do'}),\n",
    "    on=['id', 'do'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "series_temp = behav_am_df3.pop(\"start_time\")\n",
    "behav_am_df3.insert(0, \"start_time\", series_temp)\n",
    "\n",
    "behav_am_df4 = behav_am_df3.drop(index=behav_am_df3.index[behav_am_df3[\"Event_Type\"] != \"State start\"])\n",
    "\n",
    "# parse start_time (supports both 12-hour \"8:20:19 AM\"/\"8:20 AM\" and 24-hour \"18:44:45\"/\"18:44\")\n",
    "s = behav_am_df4['start_time'].astype(str).str.strip()\n",
    "# Try 12-hour formats first\n",
    "dt1 = pd.to_datetime(s, format='%I:%M:%S %p', errors='coerce')\n",
    "dt2 = pd.to_datetime(s, format='%I:%M %p', errors='coerce')\n",
    "# Try 24-hour formats\n",
    "dt3 = pd.to_datetime(s, format='%H:%M:%S', errors='coerce')\n",
    "dt4 = pd.to_datetime(s, format='%H:%M', errors='coerce')\n",
    "# Combine: try 12-hour first, then 24-hour\n",
    "behav_am_df4['start_time_dt'] = dt1.fillna(dt2).fillna(dt3).fillna(dt4)\n",
    "\n",
    "# parse Time_Relative_hmsf (supports \"HH:MM:SS(.f)\", \"MM:SS(.f)\", \"SS(.f)\")\n",
    "r = behav_am_df4['Time_Relative_hmsf'].astype(str).str.strip()\n",
    "r = r.str.replace(',', '.', regex=False).str.replace(';', '.', regex=False)\n",
    "\n",
    "td = pd.Series(pd.NaT, index=r.index, dtype='timedelta64[ns]')\n",
    "mask_hms = r.str.count(':') == 2\n",
    "mask_ms  = r.str.count(':') == 1\n",
    "mask_sec = r.str.fullmatch(r'\\d+(\\.\\d+)?')\n",
    "mask_blank = r.eq('') | r.str.lower().isin(['nan', 'none'])\n",
    "\n",
    "td.loc[mask_hms] = pd.to_timedelta(r[mask_hms], errors='coerce')\n",
    "td.loc[mask_ms]  = pd.to_timedelta('00:' + r[mask_ms], errors='coerce')  # prefix hours\n",
    "td.loc[mask_sec] = pd.to_timedelta(r[mask_sec].astype(float), unit='s')\n",
    "td.loc[mask_blank] = pd.NaT\n",
    "\n",
    "behav_am_df4['time_relative_td'] = td\n",
    "\n",
    "# sum to produce the new start time\n",
    "behav_am_df5 = behav_am_df4.copy()\n",
    "behav_am_df5['start_time_new'] = behav_am_df5['start_time_dt'] + behav_am_df5['time_relative_td']\n",
    "\n",
    "# time-only display strings (no date)\n",
    "behav_am_df5['start_time_str'] = behav_am_df5['start_time_dt'].dt.strftime('%I:%M:%S %p')\n",
    "behav_am_df5['start_time_new_str'] = behav_am_df5['start_time_new'].dt.strftime('%I:%M:%S %p')\n",
    "\n",
    "# drop intermediates, rename, and position between the first two columns\n",
    "drop_cols = [c for c in ['start_time_dt','time_relative_td','start_time_new','start_time_str'] if c in behav_am_df5.columns]\n",
    "behav_am_df5 = behav_am_df5.drop(columns=drop_cols)\n",
    "\n",
    "behav_am_df5 = behav_am_df5.rename(columns={'start_time_new_str': 'start_time_new'})\n",
    "\n",
    "first_cols = ['start_time', 'start_time_new', 'Time_Relative_hmsf']\n",
    "other_cols = [c for c in behav_am_df5.columns if c not in first_cols]\n",
    "behav_am_df5 = behav_am_df5[first_cols + other_cols]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# NEW APPROACH: Separate activity and posture tracks before expansion\n",
    "# ============================================================================\n",
    "\n",
    "# --- Helper functions (shared) ---\n",
    "def _parse_hms_to_seconds(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.str.replace(',', '.', regex=False).str.replace(';', '.', regex=False)\n",
    "\n",
    "    td = pd.Series(pd.NaT, index=s.index, dtype='timedelta64[ns]')\n",
    "    mask_hms = s.str.count(':') == 2           # H:M:S(.f)\n",
    "    mask_ms  = s.str.count(':') == 1           # M:S(.f)\n",
    "    mask_sec = s.str.fullmatch(r'\\d+(\\.\\d+)?') # seconds only\n",
    "    mask_blank = s.eq('') | r.str.lower().isin(['nan', 'none'])\n",
    "\n",
    "    td.loc[mask_hms] = pd.to_timedelta(s[mask_hms], errors='coerce')\n",
    "    td.loc[mask_ms]  = pd.to_timedelta('00:' + s[mask_ms], errors='coerce')\n",
    "    if mask_sec.any():\n",
    "        td.loc[mask_sec] = pd.to_timedelta(s[mask_sec].astype(float), unit='s')\n",
    "    td.loc[mask_blank] = pd.NaT\n",
    "\n",
    "    return td.dt.total_seconds()\n",
    "\n",
    "def _format_hms(seconds_float: float, decimals: int = 0) -> str:\n",
    "    if pd.isna(seconds_float):\n",
    "        return np.nan\n",
    "    scale = 10 ** decimals\n",
    "    total_units = int(round(seconds_float * scale))\n",
    "    secs = total_units // scale\n",
    "    frac_units = total_units % scale\n",
    "    h = secs // 3600\n",
    "    m = (secs % 3600) // 60\n",
    "    s = secs % 60\n",
    "    if decimals == 0:\n",
    "        return f'{h:02d}:{m:02d}:{s:02d}'\n",
    "    return f'{h:02d}:{m:02d}:{s:02d}.{frac_units:0{decimals}d}'\n",
    "\n",
    "# Normalization for classification\n",
    "_def_ws_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def _normalize_behavior(value: object) -> str | None:\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    s = str(value).strip().lower()\n",
    "    s = s.replace('–', '-').replace('—', '-')\n",
    "    s = _def_ws_re.sub(' ', s)\n",
    "    return s\n",
    "\n",
    "# Classify behavior as domain activity or posture\n",
    "_domain_prefixes = {\n",
    "    'sl-', 'pc-', 'ha-', 'ca-', 'wrk-', 'edu-', 'org-', 'pur-', 'eat-', 'les-', 'ex-', 'trav-', 'other-'\n",
    "}\n",
    "_posture_prefixes = {\n",
    "    'sb-', 'la-', 'wa-', 'sp-'\n",
    "}\n",
    "\n",
    "def _classify_behavior(behavior_val):\n",
    "    \"\"\"Returns 'activity', 'posture', or 'other'\"\"\"\n",
    "    norm = _normalize_behavior(behavior_val)\n",
    "    if not norm:\n",
    "        return 'other'\n",
    "    # Check domain prefixes\n",
    "    for prefix in _domain_prefixes:\n",
    "        if norm.startswith(prefix):\n",
    "            return 'activity'\n",
    "    # Check posture prefixes\n",
    "    for prefix in _posture_prefixes:\n",
    "        if norm.startswith(prefix):\n",
    "            return 'posture'\n",
    "    # Handle special cases\n",
    "    if norm in {'private/not coded', 'start posture', 'start behavior'}:\n",
    "        return 'other'\n",
    "    return 'other'\n",
    "\n",
    "df = behav_am_df5.copy()\n",
    "df['_seconds'] = _parse_hms_to_seconds(df['Time_Relative_hms'])\n",
    "df = df.sort_values(['Observation', '_seconds'], kind='mergesort')\n",
    "\n",
    "# Classify each row\n",
    "df['_track'] = df['Behavior'].apply(_classify_behavior)\n",
    "\n",
    "# Split into activity and posture dataframes\n",
    "activity_df = df[df['_track'] == 'activity'].copy()\n",
    "posture_df = df[df['_track'] == 'posture'].copy()\n",
    "\n",
    "print(f\"Activity events: {len(activity_df)}, Posture events: {len(posture_df)}, Other: {(df['_track'] == 'other').sum()}\")\n",
    "\n",
    "# --- Expand activity track to per-second ---\n",
    "def expand_track_to_seconds(track_df, track_name='track'):\n",
    "    \"\"\"Expand a track (activity or posture) to per-second resolution\"\"\"\n",
    "    out_groups = []\n",
    "    \n",
    "    for obs_value, g in track_df.groupby('Observation', sort=False):\n",
    "        g = g.copy()\n",
    "        g = g[~g['_seconds'].isna()]\n",
    "        if g.empty:\n",
    "            continue\n",
    "        \n",
    "        g['_event_second'] = np.floor(g['_seconds']).astype(int)\n",
    "        \n",
    "        # Keep last within each second\n",
    "        g_last = (\n",
    "            g.sort_values(['_event_second', '_seconds'], kind='mergesort')\n",
    "             .drop_duplicates(subset=['_event_second'], keep='last')\n",
    "        )\n",
    "        \n",
    "        min_s = float(g['_seconds'].min())\n",
    "        max_s = float(g['_seconds'].max())\n",
    "        \n",
    "        if np.isclose(min_s, 0.0):\n",
    "            start_second = 0\n",
    "            flag_first = False\n",
    "        else:\n",
    "            start_second = int(np.ceil(min_s))\n",
    "            flag_first = True\n",
    "        \n",
    "        end_second = int(np.floor(max_s))\n",
    "        if end_second < start_second:\n",
    "            end_second = start_second\n",
    "        \n",
    "        seconds_grid = np.arange(start_second, end_second + 1, dtype=int)\n",
    "        \n",
    "        base = g_last.set_index('_event_second').sort_index()\n",
    "        first_index_second = int(np.floor(min_s))\n",
    "        full_index = np.arange(first_index_second, end_second + 1, dtype=int)\n",
    "        aligned = base.reindex(full_index).ffill()\n",
    "        \n",
    "        take = aligned.loc[seconds_grid].copy()\n",
    "        take.reset_index(drop=False, inplace=True)\n",
    "        take.rename(columns={'_event_second': '_second'}, inplace=True)\n",
    "        \n",
    "        # Time strings\n",
    "        time_strings = [_format_hms(s, decimals=0) for s in seconds_grid]\n",
    "        if flag_first and len(time_strings) > 0:\n",
    "            flagged = min_s + 0.01\n",
    "            time_strings[0] = _format_hms(flagged, decimals=2)\n",
    "        \n",
    "        take['Time_Relative_hms_new'] = time_strings\n",
    "        \n",
    "        out_groups.append(take)\n",
    "    \n",
    "    if not out_groups:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    result = pd.concat(out_groups, axis=0, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "# Expand both tracks\n",
    "activity_expanded = expand_track_to_seconds(activity_df, 'activity')\n",
    "posture_expanded = expand_track_to_seconds(posture_df, 'posture')\n",
    "\n",
    "print(f\"Activity expanded: {len(activity_expanded)}, Posture expanded: {len(posture_expanded)}\")\n",
    "\n",
    "# --- Merge activity and posture on (Observation, second) ---\n",
    "# Keep columns needed from each track (including modifiers from BOTH)\n",
    "activity_cols_keep = ['Observation', '_second', 'Time_Relative_hms_new', 'Behavior', 'Modifier_1', 'Modifier_2', 'Modifier_3', \n",
    "                      'start_time_new', 'id', 'do']\n",
    "posture_cols_keep = ['Observation', '_second', 'Behavior', 'Modifier_2']  # Modifier_2 for intensity\n",
    "\n",
    "activity_subset = activity_expanded[activity_cols_keep].rename(columns={'Behavior': 'Behavior_activity', \n",
    "                                                                          'Modifier_1': 'Modifier_1_activity',\n",
    "                                                                          'Modifier_2': 'Modifier_2_activity',\n",
    "                                                                          'Modifier_3': 'Modifier_3'})\n",
    "posture_subset = posture_expanded[posture_cols_keep].rename(columns={'Behavior': 'Behavior_posture',\n",
    "                                                                       'Modifier_2': 'Modifier_2_posture'})\n",
    "\n",
    "# Full outer merge to get all seconds from both tracks\n",
    "merged = activity_subset.merge(\n",
    "    posture_subset,\n",
    "    on=['Observation', '_second'],\n",
    "    how='outer',\n",
    "    suffixes=('', '_posture')\n",
    ")\n",
    "\n",
    "# Fill observation metadata forward\n",
    "merged = merged.sort_values(['Observation', '_second'], kind='mergesort')\n",
    "for col in ['id', 'do', 'Time_Relative_hms_new', 'start_time_new']:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged.groupby('Observation')[col].ffill().bfill()\n",
    "\n",
    "# Combine Behaviors: use activity behavior for encoding activity_type, posture behavior for encoding posture\n",
    "merged['Behavior'] = merged['Behavior_activity'].fillna(merged['Behavior_posture'])\n",
    "\n",
    "# Combine Modifier_1 and Modifier_3 (activity-related modifiers)\n",
    "merged['Modifier_1'] = merged['Modifier_1_activity']\n",
    "merged['Modifier_3'] = merged['Modifier_3']\n",
    "\n",
    "# Combine Modifier_2 (intensity): prefer posture track, fallback to activity track\n",
    "merged['Modifier_2'] = merged['Modifier_2_posture'].fillna(merged['Modifier_2_activity'])\n",
    "\n",
    "# Rename _second to rel_time for final output\n",
    "merged['rel_time'] = merged['Time_Relative_hms_new']\n",
    "\n",
    "behav_am_df_6 = merged.copy()\n",
    "\n",
    "# Cleanup only intermediate helper columns, but KEEP Behavior_activity and Behavior_posture for encoding!\n",
    "for c in ['_seconds', '_second', '_track', 'Modifier_1_activity', 'Modifier_2_activity', 'Modifier_2_posture']:\n",
    "    if c in behav_am_df_6.columns:\n",
    "        behav_am_df_6 = behav_am_df_6.drop(columns=c)\n",
    "\n",
    "print(f\"Merged result: {len(behav_am_df_6)} rows\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENCODING: Activity and Posture (independent tracks, same as before)\n",
    "# ============================================================================\n",
    "\n",
    "behav_am_df_7 = behav_am_df_6.copy()\n",
    "\n",
    "# Mapping from canonical Activity_Type to (activity_type, broad_domain, waves_domain)\n",
    "_activity_type_to_meta = {\n",
    "    'SL- Sleep': ('sleep', 'sleep', 'household_personal'),\n",
    "    'PC- Groom, Health-Related': ('pc_groom', 'personal', 'household_personal'),\n",
    "    'PC- Other Personal Care': ('pc_other', 'personal', 'household_personal'),\n",
    "    'HA- Housework': ('ha_housework', 'household', 'household_personal'),\n",
    "    'HA- Food Prep and Cleanup': ('ha_food', 'household', 'household_personal'),\n",
    "    'HA- Interior Maintenance, Repair, & Decoration': ('ha_interior', 'maintenance_repair', 'household_personal'),\n",
    "    'HA- Exterior Maintenance, Repair, & Decoration': ('ha_exterior', 'maintenance_repair', 'household_personal'),\n",
    "    'HA- Lawn, Garden and Houseplants': ('ha_lawn', 'lawn_garden', 'household_personal'),\n",
    "    'HA- Animals and Pets': ('ha_pets', 'household', 'household_personal'),\n",
    "    'HA- Household Management/Other household activities': ('ha_other', 'household', 'household_personal'),\n",
    "    'CA- Caring for and Helping Children': ('care_children', 'household', 'household_personal'),\n",
    "    'CA- Caring for and Helping Adults': ('care_adults', 'household', 'household_personal'),\n",
    "    'WRK- General**': ('work_general', 'work_education', 'work_education'),\n",
    "    'WRK- Desk/Screen Based': ('work_screen', 'work_education', 'work_education'),\n",
    "    'EDU- Taking Class, Research, Homework': ('edu_class', 'work_education', 'work_education'),\n",
    "    'EDU- Extracurricular': ('edu_other', 'work_education', 'work_education'),\n",
    "    'ORG- Church, Spiritual': ('com_church', 'purchase_other', 'purchase_other'),\n",
    "    'Volunteer Work (ORG - Volunteer Work)': ('com_volunteer', 'purchase_other', 'purchase_other'),\n",
    "    'PUR- Purchasing Goods and Services': ('com_purchase', 'purchase_other', 'purchase_other'),\n",
    "    'EAT- Eating and Drinking, Waiting': ('ha_eat', 'personal', 'household_personal'),\n",
    "    'LES- Socializing, Communicating, Non-Screen Based': ('les_social', 'leisure', 'leisure'),\n",
    "    'LES- Screen-Based (TV, Video Game, Computer, Phone)': ('les_screen', 'Leisure_Screen', 'leisure'),\n",
    "    'EX- Participating in Sport, Exercise or Recreation***': ('ex_sport', 'exercise', 'leisure'),\n",
    "    'EX- Attending Sport, Exercise Recreation Event, or Performance': ('les_attend', 'leisure', 'leisure'),\n",
    "    'TRAV- Passenger (Car/Truck/Motorcycle)': ('trav_pass', 'Trav_car', 'transportation'),\n",
    "    'TRAV- Driver (Car/Truck/Motorcycle)': ('trav_drive', 'Trav_car', 'transportation'),\n",
    "    'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)': ('trav_pass', 'Trav_public', 'transportation'),\n",
    "    'TRAV- Biking': ('trav_bike', 'active_transportation', 'transportation'),\n",
    "    'TRAV-Walking': ('trav_walk', 'active_transportation', 'transportation'),\n",
    "    'TRAV- General': ('trav_other', 'transportation', 'transportation'),\n",
    "    'OTHER- Non-Codable (delete these rows from dataset)': ('non_codable', 'non_codable', 'non_codable'),\n",
    "}\n",
    "\n",
    "# Map raw Behavior values to canonical Activity_Type keys above\n",
    "_alias_to_activity_type = {\n",
    "    'sl- sleep': 'SL- Sleep',\n",
    "    'pc- groom, health-related': 'PC- Groom, Health-Related',\n",
    "    'pc- other personal care': 'PC- Other Personal Care',\n",
    "    'ha- housework': 'HA- Housework',\n",
    "    'ha- food prep and cleanup': 'HA- Food Prep and Cleanup',\n",
    "    'ha- interior maintenance, repair, & decoration': 'HA- Interior Maintenance, Repair, & Decoration',\n",
    "    'ha- exterior maintenance, repair, & decoration': 'HA- Exterior Maintenance, Repair, & Decoration',\n",
    "    'ha- lawn, garden and houseplants': 'HA- Lawn, Garden and Houseplants',\n",
    "    'ha- animals and pets': 'HA- Animals and Pets',\n",
    "    'ha- household management/other household activities': 'HA- Household Management/Other household activities',\n",
    "    'ca- caring for and helping children': 'CA- Caring for and Helping Children',\n",
    "    'ca- caring for and helping adults': 'CA- Caring for and Helping Adults',\n",
    "    'wrk- general': 'WRK- General**',\n",
    "    'wrk- screen based': 'WRK- Desk/Screen Based',\n",
    "    'edu- taking class, research, homework': 'EDU- Taking Class, Research, Homework',\n",
    "    'edu- extracurricular': 'EDU- Extracurricular',\n",
    "    'org- church, spiritual': 'ORG- Church, Spiritual',\n",
    "    'org- volunteer': 'Volunteer Work (ORG - Volunteer Work)',\n",
    "    'pur- purchasing goods and services': 'PUR- Purchasing Goods and Services',\n",
    "    'eat- eating and drinking, waiting': 'EAT- Eating and Drinking, Waiting',\n",
    "    'les- socializing, communicating, leisure time not screen': 'LES- Socializing, Communicating, Non-Screen Based',\n",
    "    'les- screen based leisure time (tv, video game, computer)': 'LES- Screen-Based (TV, Video Game, Computer, Phone)',\n",
    "    'les- screen-based (tv, video game, computer, phone)': 'LES- Screen-Based (TV, Video Game, Computer, Phone)',\n",
    "    'ex- participating in sport, exercise or recreation': 'EX- Participating in Sport, Exercise or Recreation***',\n",
    "    'ex- attending sport, recreational event, or performance': 'EX- Attending Sport, Exercise Recreation Event, or Performance',\n",
    "    'trav- passenger (car/truck/motorcycle)': 'TRAV- Passenger (Car/Truck/Motorcycle)',\n",
    "    'trav- driver (car/truck/motorcycle)': 'TRAV- Driver (Car/Truck/Motorcycle)',\n",
    "    'trav- passenger (bus, train, tram, plane, boat, ship)': 'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)',\n",
    "    'trav- biking': 'TRAV- Biking',\n",
    "    'trav- walking': 'TRAV-Walking',\n",
    "    'trav-walking': 'TRAV-Walking',\n",
    "    'trav- general': 'TRAV- General',\n",
    "    'other- non codable': 'OTHER- Non-Codable (delete these rows from dataset)',\n",
    "    'private/not coded': 'OTHER- Non-Codable (delete these rows from dataset)',\n",
    "}\n",
    "\n",
    "def _map_behavior_to_activity_type(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('les- screen'):\n",
    "        return 'LES- Screen-Based (TV, Video Game, Computer, Phone)'\n",
    "    if s.startswith('trav- passenger (bus'):\n",
    "        return 'TRAV- Passenger (Bus, Train, Tram, Plane, Boat, Ship)'\n",
    "    return _alias_to_activity_type.get(s)\n",
    "\n",
    "# Build Activity_Type from Behavior_activity column (preserved from activity track)\n",
    "if 'Behavior_activity' in behav_am_df_7.columns:\n",
    "    behav_am_df_7['Activity_Type'] = behav_am_df_7['Behavior_activity'].apply(_map_behavior_to_activity_type)\n",
    "else:\n",
    "    # Fallback: classify on the fly from merged Behavior\n",
    "    behav_am_df_7['Activity_Type'] = behav_am_df_7['Behavior'].apply(\n",
    "        lambda b: _map_behavior_to_activity_type(b) if _classify_behavior(b) == 'activity' else None\n",
    "    )\n",
    "\n",
    "# EX modifier handling\n",
    "if 'Modifier_1' in behav_am_df_7.columns:\n",
    "    mask_ex = behav_am_df_7['Activity_Type'] == 'EX- Participating in Sport, Exercise or Recreation***'\n",
    "    mask_m1 = behav_am_df_7['Modifier_1'].notna()\n",
    "    mask_apply = mask_ex & mask_m1\n",
    "    if mask_apply.any():\n",
    "        mod1_norm = (\n",
    "            behav_am_df_7.loc[mask_apply, 'Modifier_1']\n",
    "            .astype(str).str.strip().str.lower()\n",
    "            .str.replace(r'\\s+', '-', regex=True).str.replace('/', '-')\n",
    "        )\n",
    "        behav_am_df_7.loc[mask_apply, 'Activity_Type'] = 'EX-' + mod1_norm\n",
    "\n",
    "# work_type from Modifier_3\n",
    "work_labels = {'WRK- General**', 'WRK- Desk/Screen Based'}\n",
    "if 'Modifier_3' in behav_am_df_7.columns:\n",
    "    def _mk_work_type(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        raw = str(x).strip()\n",
    "        raw = re.sub(r'^\\s*sp-\\s*', '', raw, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"\\s+\", '_', raw.lower()).replace('/', '_')\n",
    "        s = s.replace('hospiltality', 'hospitality')\n",
    "        return f\"work_{s}\" if s else np.nan\n",
    "    behav_am_df_7['work_type_raw'] = behav_am_df_7['Modifier_3'].apply(_mk_work_type)\n",
    "else:\n",
    "    behav_am_df_7['work_type_raw'] = np.nan\n",
    "\n",
    "# Expand Activity_Type to three encoded columns\n",
    "cols = ['activity_type', 'broad_domain', 'waves_domain']\n",
    "\n",
    "def _activity_meta_lookup(activity_type: object):\n",
    "    if isinstance(activity_type, str) and activity_type.startswith('EX-'):\n",
    "        return ('ex_sport', 'exercise', 'leisure')\n",
    "    return _activity_type_to_meta.get(activity_type)\n",
    "\n",
    "behav_am_df_7[cols] = behav_am_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "    lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    ")\n",
    "\n",
    "# Detect grouping\n",
    "if 'Observation' in behav_am_df_7.columns:\n",
    "    _group_cols = ['Observation']\n",
    "elif {'id','do'}.issubset(behav_am_df_7.columns):\n",
    "    _group_cols = ['id','do']\n",
    "else:\n",
    "    _group_cols = None\n",
    "\n",
    "# Forward-fill Activity_Type within observation\n",
    "if _group_cols is not None:\n",
    "    behav_am_df_7['Activity_Type'] = behav_am_df_7.groupby(_group_cols)['Activity_Type'].ffill()\n",
    "    behav_am_df_7[cols] = behav_am_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "        lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    "    )\n",
    "\n",
    "# Posture encoding\n",
    "def _map_posture_wbm_from_behavior(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('sb-sitting'):\n",
    "        return 'sitting'\n",
    "    if s.startswith('sb-lying') or s.startswith('sb- lying'):\n",
    "        return 'lying'\n",
    "    if s.startswith('la- kneeling'):\n",
    "        return 'kneel_squat'\n",
    "    if s == 'la- stretching':\n",
    "        return 'stretch'\n",
    "    if s == 'la- stand and move':\n",
    "        return 'stand_move'\n",
    "    if s == 'la- stand':\n",
    "        return 'stand'\n",
    "    if s in {'wa- walk', 'wa- walking', 'trav- walking', 'trav-walking'}:\n",
    "        return 'walk'\n",
    "    if s in {'wa-walk with load', 'wa- walk with load'}:\n",
    "        return 'walk_load'\n",
    "    if s == 'wa- ascend stairs':\n",
    "        return 'ascend'\n",
    "    if s == 'wa- descend stairs':\n",
    "        return 'descend'\n",
    "    if s == 'wa- running':\n",
    "        return 'running'\n",
    "    if s == 'sp- bike':\n",
    "        return 'biking'\n",
    "    if s in {'sp- other sport movement', 'sp- swing', 'sp -kick', 'sp- jump'}:\n",
    "        return 'sport_move'\n",
    "    if s == 'sp- muscle strengthening':\n",
    "        return 'muscle_strength'\n",
    "    if s == 'private/not coded':\n",
    "        return 'not_coded'\n",
    "    return None\n",
    "\n",
    "_posture_meta = {\n",
    "    'sitting': ('sedentary', 'sedentary'),\n",
    "    'lying': ('sedentary', 'sedentary'),\n",
    "    'kneel_squat': ('sedentary', 'mixed_move'),\n",
    "    'stretch': ('sport', 'sport'),\n",
    "    'stand': ('stand_move', 'mixed_move'),\n",
    "    'stand_move': ('stand_move', 'mixed_move'),\n",
    "    'walk': ('walk', 'walk'),\n",
    "    'walk_load': ('mod_walk', 'walk'),\n",
    "    'ascend': ('mod_walk', 'walk'),\n",
    "    'descend': ('mod_walk', 'walk'),\n",
    "    'running': ('running', 'running'),\n",
    "    'biking': ('biking', 'biking'),\n",
    "    'sport_move': ('sport', 'sport'),\n",
    "    'muscle_strength': ('sport', 'sport'),\n",
    "    'not_coded': ('not_coded', 'not_coded'),\n",
    "}\n",
    "\n",
    "# Build posture from Behavior_posture column (preserved from posture track)\n",
    "# CRITICAL: must use Behavior_posture, not merged Behavior, to avoid losing posture when both activity and posture exist at same second\n",
    "if 'Behavior_posture' in behav_am_df_7.columns:\n",
    "    behav_am_df_7['posture_wbm'] = behav_am_df_7['Behavior_posture'].apply(_map_posture_wbm_from_behavior)\n",
    "else:\n",
    "    # fallback: try to extract from merged Behavior (but this will miss simultaneous events)\n",
    "    behav_am_df_7['posture_wbm'] = behav_am_df_7['Behavior'].apply(\n",
    "        lambda b: _map_posture_wbm_from_behavior(b) if _classify_behavior(b) == 'posture' else None\n",
    "    )\n",
    "\n",
    "_broad_waves = behav_am_df_7['posture_wbm'].map(lambda k: _posture_meta.get(k, (np.nan, np.nan)))\n",
    "behav_am_df_7[['posture_broad', 'posture_waves']] = pd.DataFrame(_broad_waves.tolist(), index=behav_am_df_7.index)\n",
    "\n",
    "# Forward-fill posture within observation\n",
    "if _group_cols is not None:\n",
    "    for _c in ['posture_wbm', 'posture_broad', 'posture_waves']:\n",
    "        behav_am_df_7[_c] = behav_am_df_7.groupby(_group_cols)[_c].ffill()\n",
    "\n",
    "# waves_sedentary\n",
    "def _waves_sed_vec(posture_wbm, activity_type):\n",
    "    \"\"\"Vectorized waves_sedentary computation\"\"\"\n",
    "    result = pd.Series(index=posture_wbm.index, dtype='object')\n",
    "    \n",
    "    mask_sit = posture_wbm == 'sitting'\n",
    "    mask_drive = activity_type.isin({'trav_drive', 'trav_pass'})\n",
    "    result.loc[mask_sit & mask_drive] = 'sed_drive'\n",
    "    result.loc[mask_sit & ~mask_drive] = 'sedentary'\n",
    "    \n",
    "    mask_lying_kneel = posture_wbm.isin({'lying', 'kneel_squat'})\n",
    "    result.loc[mask_lying_kneel] = 'sedentary'\n",
    "    \n",
    "    mask_active = posture_wbm.notna() & ~mask_sit & ~mask_lying_kneel\n",
    "    result.loc[mask_active] = 'active'\n",
    "    \n",
    "    return result\n",
    "\n",
    "behav_am_df_7['waves_sedentary'] = _waves_sed_vec(behav_am_df_7['posture_wbm'], behav_am_df_7['activity_type'])\n",
    "\n",
    "# Intensity encoding\n",
    "# intensity typically comes from posture events (sb-, la-, wa-, sp-) so use Behavior_posture first\n",
    "def _posture_intensity(value: object) -> str | None:\n",
    "    s = _normalize_behavior(value)\n",
    "    if not s:\n",
    "        return None\n",
    "    if s.startswith('sb-sitting') or s.startswith('sb-lying') or s.startswith('sb- lying') or s.startswith('la- kneeling'):\n",
    "        return 'sedentary'\n",
    "    if s in {'la- stand', 'la- stand and move', 'la- stretching'}:\n",
    "        return 'light'\n",
    "    return None\n",
    "\n",
    "# try posture behavior first, then fall back to merged behavior\n",
    "if 'Behavior_posture' in behav_am_df_7.columns:\n",
    "    behav_am_df_7['intensity'] = behav_am_df_7['Behavior_posture'].apply(_posture_intensity)\n",
    "    # fill from activity behavior where posture didn't provide intensity\n",
    "    _mask_missing = behav_am_df_7['intensity'].isna()\n",
    "    behav_am_df_7.loc[_mask_missing, 'intensity'] = behav_am_df_7.loc[_mask_missing, 'Behavior_activity'].apply(_posture_intensity)\n",
    "else:\n",
    "    behav_am_df_7['intensity'] = behav_am_df_7['Behavior'].apply(_posture_intensity)\n",
    "\n",
    "# Fill from Modifier_2 only where intensity is still missing\n",
    "if 'Modifier_2' in behav_am_df_7.columns:\n",
    "    def _norm_intensity(m) -> str | None:\n",
    "        if pd.isna(m):\n",
    "            return None\n",
    "        s = str(m).strip().lower()\n",
    "        if not s:\n",
    "            return None\n",
    "        if s.startswith('vig'):\n",
    "            return 'vigorous'\n",
    "        if s.startswith('mod'):\n",
    "            return 'moderate'\n",
    "        if s == 'light':\n",
    "            return 'light'\n",
    "        if s == 'sedentary':\n",
    "            return 'sedentary'\n",
    "        return None\n",
    "    _mask_missing = behav_am_df_7['intensity'].isna()\n",
    "    behav_am_df_7.loc[_mask_missing, 'intensity'] = behav_am_df_7.loc[_mask_missing, 'Modifier_2'].apply(_norm_intensity)\n",
    "\n",
    "# Forward-fill intensity within observation\n",
    "if _group_cols is not None:\n",
    "    behav_am_df_7['intensity'] = behav_am_df_7.groupby(_group_cols)['intensity'].ffill()\n",
    "\n",
    "# waves_intensity\n",
    "behav_am_df_7['waves_intensity'] = behav_am_df_7['intensity'].map(lambda x: 'mvpa' if x in {'moderate', 'vigorous'} else x)\n",
    "\n",
    "# Finalize work_type\n",
    "if 'work_type_raw' in behav_am_df_7.columns:\n",
    "    if _group_cols is not None:\n",
    "        behav_am_df_7['work_type_raw'] = behav_am_df_7.groupby(_group_cols)['work_type_raw'].ffill()\n",
    "    behav_am_df_7['work_type'] = np.where(\n",
    "        behav_am_df_7['Activity_Type'].isin(work_labels),\n",
    "        behav_am_df_7['work_type_raw'],\n",
    "        np.nan,\n",
    "    )\n",
    "    behav_am_df_7 = behav_am_df_7.drop(columns=['work_type_raw'])\n",
    "\n",
    "# Drop non-codable\n",
    "_non_codable_mask = (\n",
    "    behav_am_df_7['Activity_Type'] == 'OTHER- Non-Codable (delete these rows from dataset)'\n",
    ") | (\n",
    "    behav_am_df_7['Behavior'].astype(str).str.strip().str.lower().isin(['private/not coded'])\n",
    ")\n",
    "behav_am_df_7 = behav_am_df_7.loc[~_non_codable_mask].copy()\n",
    "\n",
    "print(f\"After encoding, behav_am_df_7 shape: {behav_am_df_7.shape}\")\n",
    "print(f\"activity_type NaN: {behav_am_df_7['activity_type'].isna().sum()}\")\n",
    "print(f\"posture_wbm NaN: {behav_am_df_7['posture_wbm'].isna().sum()}\")\n",
    "\n",
    "# Stabilize both tracks with ffill+bfill\n",
    "if _group_cols is not None:\n",
    "    # Activity track\n",
    "    _before_act = behav_am_df_7['Activity_Type'].isna().sum()\n",
    "    ff_act = behav_am_df_7.groupby(_group_cols, sort=False)['Activity_Type'].ffill()\n",
    "    bf_act = behav_am_df_7.groupby(_group_cols, sort=False)['Activity_Type'].bfill()\n",
    "    behav_am_df_7['Activity_Type'] = ff_act.fillna(bf_act)\n",
    "    \n",
    "    # Recompute activity meta\n",
    "    behav_am_df_7[cols] = behav_am_df_7['Activity_Type'].map(_activity_meta_lookup).apply(\n",
    "        lambda tpl: pd.Series(tpl if isinstance(tpl, tuple) else (np.nan, np.nan, np.nan))\n",
    "    )\n",
    "    _after_act = behav_am_df_7['Activity_Type'].isna().sum()\n",
    "    \n",
    "    # Posture track\n",
    "    _before_pos = behav_am_df_7['posture_wbm'].isna().sum()\n",
    "    ff_pos = behav_am_df_7.groupby(_group_cols, sort=False)['posture_wbm'].ffill()\n",
    "    bf_pos = behav_am_df_7.groupby(_group_cols, sort=False)['posture_wbm'].bfill()\n",
    "    behav_am_df_7['posture_wbm'] = ff_pos.fillna(bf_pos)\n",
    "    \n",
    "    # Recompute posture meta\n",
    "    _pw = behav_am_df_7['posture_wbm'].map(lambda k: _posture_meta.get(k, (np.nan, np.nan)))\n",
    "    behav_am_df_7[['posture_broad', 'posture_waves']] = pd.DataFrame(_pw.tolist(), index=behav_am_df_7.index)\n",
    "    _after_pos = behav_am_df_7['posture_wbm'].isna().sum()\n",
    "    \n",
    "    # Recompute waves_sedentary\n",
    "    behav_am_df_7['waves_sedentary'] = _waves_sed_vec(behav_am_df_7['posture_wbm'], behav_am_df_7['activity_type'])\n",
    "    \n",
    "    print(f\"Stabilization: activity_type {_before_act} -> {_after_act}, posture_wbm {_before_pos} -> {_after_pos}\")\n",
    "\n",
    "# Final cleanup: drop Behavior_activity and Behavior_posture now that encoding is complete\n",
    "for c in ['Behavior_activity', 'Behavior_posture']:\n",
    "    if c in behav_am_df_7.columns:\n",
    "        behav_am_df_7 = behav_am_df_7.drop(columns=c)\n",
    "        \n",
    "# Build behav_copy for final output\n",
    "# First, merge 'date' from log_df since it may have been lost during track merging\n",
    "behav_am_df_7_with_date = behav_am_df_7.merge(\n",
    "    log_df[['id', 'do', 'date']],\n",
    "    on=['id', 'do'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "behav_copy = behav_am_df_7_with_date[[\"id\", \"do\", \"Time_Relative_hms_new\", \"activity_type\", \"posture_waves\", \"intensity\", \"start_time_new\", \"date\"]].copy()\n",
    "behav_copy = behav_copy.rename(columns={\"do\": \"obs\", \"Time_Relative_hms_new\": \"rel_time\", \"start_time_new\": \"time\"})\n",
    "\n",
    "# Create date_time column: date + \" \" + time\n",
    "# Convert time to string if it's datetime, then combine with date\n",
    "if pd.api.types.is_datetime64_any_dtype(behav_copy['time']):\n",
    "    behav_copy['time'] = behav_copy['time'].dt.strftime('%I:%M:%S %p')\n",
    "behav_copy['date_time'] = behav_copy['date'].astype(str) + \" \" + behav_copy['time'].astype(str)\n",
    "\n",
    "# Reorder columns to exact specification: id, obs, date, time, date_time, rel_time, activity_type, posture_waves, intensity\n",
    "behav_copy = behav_copy[[\"id\", \"obs\", \"date\", \"time\", \"date_time\", \"rel_time\", \"activity_type\", \"posture_waves\", \"intensity\"]]\n",
    "\n",
    "behav_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeae9492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>date_time</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>posture_waves</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:47:26 PM</td>\n",
       "      <td>10/3/2017 06:47:26 PM</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>les_screen</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sedentary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  obs       date         time              date_time  rel_time  \\\n",
       "1000  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1001  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1002  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1003  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1004  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1005  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1006  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1007  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1008  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "1009  1.0  1.0  10/3/2017  06:47:26 PM  10/3/2017 06:47:26 PM  00:02:41   \n",
       "\n",
       "     activity_type posture_waves  intensity  \n",
       "1000    les_screen     sedentary  sedentary  \n",
       "1001    les_screen     sedentary  sedentary  \n",
       "1002    les_screen     sedentary  sedentary  \n",
       "1003    les_screen     sedentary  sedentary  \n",
       "1004    les_screen     sedentary  sedentary  \n",
       "1005    les_screen     sedentary  sedentary  \n",
       "1006    les_screen     sedentary  sedentary  \n",
       "1007    les_screen     sedentary  sedentary  \n",
       "1008    les_screen     sedentary  sedentary  \n",
       "1009    les_screen     sedentary  sedentary  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_copy.iloc[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfe71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully exported behav_copy to 'Cameron_AM_Clean.csv'\n",
      "  Rows: 1,177,432\n",
      "  Columns: ['id', 'obs', 'date', 'time', 'date_time', 'rel_time', 'activity_type', 'posture_waves', 'intensity']\n"
     ]
    }
   ],
   "source": [
    "# Export behav_copy to CSV\n",
    "behav_copy.to_csv(\"Cameron_AM_Clean.csv\", index=False)\n",
    "\n",
    "print(\"✓ Successfully exported behav_copy to 'Cameron_AM_Clean.csv'\")\n",
    "print(f\"  Rows: {len(behav_copy):,}\")\n",
    "print(f\"  Columns: {list(behav_copy.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04b834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obs</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>date_time</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>posture_waves</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>06:44:45 PM</td>\n",
       "      <td>10/3/2017 06:44:45 PM</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>les_social</td>\n",
       "      <td>mixed_move</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  obs       date         time              date_time  rel_time  \\\n",
       "0  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:00   \n",
       "1  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:01   \n",
       "2  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:02   \n",
       "3  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:03   \n",
       "4  1.0  1.0  10/3/2017  06:44:45 PM  10/3/2017 06:44:45 PM  00:00:04   \n",
       "\n",
       "  activity_type posture_waves intensity  \n",
       "0    les_social    mixed_move     light  \n",
       "1    les_social    mixed_move     light  \n",
       "2    les_social    mixed_move     light  \n",
       "3    les_social    mixed_move     light  \n",
       "4    les_social    mixed_move     light  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_copy.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
